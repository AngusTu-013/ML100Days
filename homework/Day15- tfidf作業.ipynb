{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標：搭建一個TFIDF 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference:https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "documentA = 'the man went out for a walk'\n",
    "documentB = 'the children sat around the fire'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先我們做tokenize，並取出所有文件中的單詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenize_A = nltk.word_tokenize(documentA)\n",
    "tokenize_B = nltk.word_tokenize(documentB)\n",
    "\n",
    "# union() 方法返回两个集合的并集，即包含了所有集合的元素，重复的元素只会出现一次。\n",
    "uniqueWords = set(tokenize_A).union(set(tokenize_B)) ##所有文件中的單詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'man', 'went', 'out', 'for', 'a', 'walk']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'children', 'sat', 'around', 'the', 'fire']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'for', 'man', 'out', 'the', 'walk', 'went'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tokenize_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'around', 'children', 'fire', 'sat', 'the'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tokenize_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'around',\n",
       " 'children',\n",
       " 'fire',\n",
       " 'for',\n",
       " 'man',\n",
       " 'out',\n",
       " 'sat',\n",
       " 'the',\n",
       " 'walk',\n",
       " 'went'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算每個文件中，所有uniqueWords出現的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for word in tokenize_A:\n",
    "    numOfWordsA[word] += 1\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for word in tokenize_B:\n",
    "    numOfWordsB[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the', 'man', 'went', 'out', 'for', 'a', 'walk'],\n",
       " {'a': 1,\n",
       "  'around': 0,\n",
       "  'children': 0,\n",
       "  'fire': 0,\n",
       "  'for': 1,\n",
       "  'man': 1,\n",
       "  'out': 1,\n",
       "  'sat': 0,\n",
       "  'the': 1,\n",
       "  'walk': 1,\n",
       "  'went': 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_A, numOfWordsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the', 'children', 'sat', 'around', 'the', 'fire'],\n",
       " {'a': 0,\n",
       "  'around': 1,\n",
       "  'children': 1,\n",
       "  'fire': 1,\n",
       "  'for': 0,\n",
       "  'man': 0,\n",
       "  'out': 0,\n",
       "  'sat': 1,\n",
       "  'the': 2,\n",
       "  'walk': 0,\n",
       "  'went': 0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_B, numOfWordsB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義function:計算TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, tokenize_item):\n",
    "    \"\"\"\n",
    "    wordDict : 文件內單詞對應出現數量的字典\n",
    "    tokenize_item : 文件tokenize後的輸出\n",
    "    \"\"\"\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(tokenize_item) ## tokenize_item單詞數量; 分母就是統計文件中每個詞出現次數的總和，也即是一篇文件中總詞數。\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bagOfWordsCount) ##單詞在該文件出現的次數/該文件擁有的所有單詞數量\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.14285714285714285,\n",
       " 'around': 0.0,\n",
       " 'children': 0.0,\n",
       " 'fire': 0.0,\n",
       " 'for': 0.14285714285714285,\n",
       " 'man': 0.14285714285714285,\n",
       " 'out': 0.14285714285714285,\n",
       " 'sat': 0.0,\n",
       " 'the': 0.14285714285714285,\n",
       " 'walk': 0.14285714285714285,\n",
       " 'went': 0.14285714285714285}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfA = computeTF(numOfWordsA, tokenize_A)\n",
    "tfA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義function:計算IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeIDF(documentsDict):\n",
    "    \"\"\"\n",
    "    documentsDict:為一個list，包含所有文件的wordDict\n",
    "    \"\"\"\n",
    "    import math\n",
    "    N = len(documentsDict)  # N= 文章總數\n",
    "    \n",
    "    idfDict = dict.fromkeys(documentsDict[0].keys(), 0)\n",
    "    for document in documentsDict:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1 ## 計算單詞在多少文件中出現過\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N/float(val)) ## 計算IDF，Log (所有文件的數目/包含這個單詞的文件數目) #math.log(tt_count / (1.0 + v))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.6931471805599453,\n",
       " 'around': 0.6931471805599453,\n",
       " 'children': 0.6931471805599453,\n",
       " 'fire': 0.6931471805599453,\n",
       " 'for': 0.6931471805599453,\n",
       " 'man': 0.6931471805599453,\n",
       " 'out': 0.6931471805599453,\n",
       " 'sat': 0.6931471805599453,\n",
       " 'the': 0.0,\n",
       " 'walk': 0.6931471805599453,\n",
       " 'went': 0.6931471805599453}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義function:計算TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeTFIDF(tf_item, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tf_item.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfA = computeTF(numOfWordsA, tokenize_A)\n",
    "tfB = computeTF(numOfWordsB, tokenize_B)\n",
    "\n",
    "idfs = computeIDF([numOfWordsA, numOfWordsB])\n",
    "\n",
    "\n",
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.09902102579427789,\n",
       " 'around': 0.0,\n",
       " 'children': 0.0,\n",
       " 'fire': 0.0,\n",
       " 'for': 0.09902102579427789,\n",
       " 'man': 0.09902102579427789,\n",
       " 'out': 0.09902102579427789,\n",
       " 'sat': 0.0,\n",
       " 'the': 0.0,\n",
       " 'walk': 0.09902102579427789,\n",
       " 'went': 0.09902102579427789}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.0,\n",
       " 'around': 0.11552453009332421,\n",
       " 'children': 0.11552453009332421,\n",
       " 'fire': 0.11552453009332421,\n",
       " 'for': 0.0,\n",
       " 'man': 0.0,\n",
       " 'out': 0.0,\n",
       " 'sat': 0.11552453009332421,\n",
       " 'the': 0.0,\n",
       " 'walk': 0.0,\n",
       " 'went': 0.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
