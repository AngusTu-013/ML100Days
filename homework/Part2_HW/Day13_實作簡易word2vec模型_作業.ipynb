{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 實作word2vec Skip-gram模型\n",
    "在課程中了解如何搭建CBOW模型，這次的作業目的在於透過搭建Skip-gram模型來了解另外一種word2vec的架構。\n",
    "\n",
    "Hint_1: 學員可以善用課程中以搭建好的function模組\n",
    "Hint_2: Skip_gram所需的輸入資料與目標跟CBOW有些許不同，Skip_gram是由中間字詞預測上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from utils.utility import clip_grads, convert_one_hot, preprocess, Trainer\n",
    "from utils.layers import Dense, SoftmaxWithCrossEntropy\n",
    "from utils.optimizer import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 6, 5, 4, 7]),\n",
       " array([[1, 2],\n",
       "        [0, 6],\n",
       "        [2, 5],\n",
       "        [6, 4],\n",
       "        [5, 7],\n",
       "        [4, 3]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the same corpus as in the lecture\n",
    "text = \"I am studying Natural Language Processing now.\"\n",
    "\n",
    "# define create_contexts_target function\n",
    "def create_contexts_target(corpus: List, window_size: int=1):\n",
    "\n",
    "    ###<your code>###\n",
    "    contexts = corpus[window_size:-window_size]\n",
    "    targets = []\n",
    "\n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                # skip target word itself\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        targets.append(cs)\n",
    "\n",
    "    return np.array(contexts), np.array(targets)\n",
    "\n",
    "# transform corpus to contexts and targets pair\n",
    "corpus, word2idx, idx2word = preprocess([text])\n",
    "contexts, targets= create_contexts_target(corpus[0], window_size=1)\n",
    "contexts, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1]]),\n",
       " array([[[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0, 0, 0]],\n",
       " \n",
       "        [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0]],\n",
       " \n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " \n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0]]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform contexts and targets to one-hot encoding\n",
    "### <your code> ###\n",
    "contexts = convert_one_hot(contexts, len(word2idx))\n",
    "targets = convert_one_hot(targets, len(word2idx))\n",
    "contexts , targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Skip-gram model\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # initialize weights\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "\n",
    "        # create layers\n",
    "        self.in_layer = Dense(W_in) ### <your code> ###\n",
    "        self.out_layer = Dense(W_out) ### <your code> ###\n",
    "        self.loss_layers = [SoftmaxWithCrossEntropy() for i in range(window_size*2)] ### <your code> ###\n",
    "        \n",
    "\n",
    "        layers = [self.in_layer , self.out_layer] ### <your code> ###\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        # word vector matrix\n",
    "        self.word_vecs = W_in ### <your code> ###\n",
    "\n",
    "    def forward(self, contexts, targets):\n",
    "        h = self.in_layer.forward(contexts) ### <your code> ###\n",
    "        s = self.out_layer.forward(h) ### <your code> ###\n",
    "        \n",
    "        loss = sum([self.loss_layers[i].forward(s, targets[:, i]) for i in range(self.window_size*2)]) ### <your code> ###\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        \n",
    "        ds = sum([self.loss_layers[i].backward(dout) for i in range(self.window_size*2)]) ### <your code> ###\n",
    "        dh = self.out_layer.backward(ds) ### <your code> ###\n",
    "        self.in_layer.backward(dh)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▎                             | 219/1000 [00:00<00:00, 986.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iteration: 1/2, Loss: 4.1589232163140775\n",
      "Epoch: 2, Iteration: 1/2, Loss: 4.159081301941605\n",
      "Epoch: 3, Iteration: 1/2, Loss: 4.158842138951027\n",
      "Epoch: 4, Iteration: 1/2, Loss: 4.158957258878937\n",
      "Epoch: 5, Iteration: 1/2, Loss: 4.158970815613211\n",
      "Epoch: 6, Iteration: 1/2, Loss: 4.158754707578931\n",
      "Epoch: 7, Iteration: 1/2, Loss: 4.158801184732305\n",
      "Epoch: 8, Iteration: 1/2, Loss: 4.158763427555511\n",
      "Epoch: 9, Iteration: 1/2, Loss: 4.158707384029009\n",
      "Epoch: 10, Iteration: 1/2, Loss: 4.158645297819965\n",
      "Epoch: 11, Iteration: 1/2, Loss: 4.158658834849007\n",
      "Epoch: 12, Iteration: 1/2, Loss: 4.1585202062703175\n",
      "Epoch: 13, Iteration: 1/2, Loss: 4.158645328049097\n",
      "Epoch: 14, Iteration: 1/2, Loss: 4.158470273689979\n",
      "Epoch: 15, Iteration: 1/2, Loss: 4.158352575816524\n",
      "Epoch: 16, Iteration: 1/2, Loss: 4.158290985298649\n",
      "Epoch: 17, Iteration: 1/2, Loss: 4.158209382438979\n",
      "Epoch: 18, Iteration: 1/2, Loss: 4.158486756265215\n",
      "Epoch: 19, Iteration: 1/2, Loss: 4.157998143447827\n",
      "Epoch: 20, Iteration: 1/2, Loss: 4.157947542680512\n",
      "Epoch: 21, Iteration: 1/2, Loss: 4.157986695366546\n",
      "Epoch: 22, Iteration: 1/2, Loss: 4.157745163877671\n",
      "Epoch: 23, Iteration: 1/2, Loss: 4.157681545778528\n",
      "Epoch: 24, Iteration: 1/2, Loss: 4.1573158334403635\n",
      "Epoch: 25, Iteration: 1/2, Loss: 4.1574263267852904\n",
      "Epoch: 26, Iteration: 1/2, Loss: 4.157069883508239\n",
      "Epoch: 27, Iteration: 1/2, Loss: 4.157277692789242\n",
      "Epoch: 28, Iteration: 1/2, Loss: 4.156718149786196\n",
      "Epoch: 29, Iteration: 1/2, Loss: 4.156309392040982\n",
      "Epoch: 30, Iteration: 1/2, Loss: 4.156515376912358\n",
      "Epoch: 31, Iteration: 1/2, Loss: 4.156302370322129\n",
      "Epoch: 32, Iteration: 1/2, Loss: 4.1552608879742685\n",
      "Epoch: 33, Iteration: 1/2, Loss: 4.155668335003864\n",
      "Epoch: 34, Iteration: 1/2, Loss: 4.154282995179864\n",
      "Epoch: 35, Iteration: 1/2, Loss: 4.153768933276736\n",
      "Epoch: 36, Iteration: 1/2, Loss: 4.153429364563566\n",
      "Epoch: 37, Iteration: 1/2, Loss: 4.154909838712407\n",
      "Epoch: 38, Iteration: 1/2, Loss: 4.151236629483053\n",
      "Epoch: 39, Iteration: 1/2, Loss: 4.152781358179789\n",
      "Epoch: 40, Iteration: 1/2, Loss: 4.149877497965633\n",
      "Epoch: 41, Iteration: 1/2, Loss: 4.149574949897879\n",
      "Epoch: 42, Iteration: 1/2, Loss: 4.149625141430004\n",
      "Epoch: 43, Iteration: 1/2, Loss: 4.145650268236929\n",
      "Epoch: 44, Iteration: 1/2, Loss: 4.149241529424683\n",
      "Epoch: 45, Iteration: 1/2, Loss: 4.146940742960083\n",
      "Epoch: 46, Iteration: 1/2, Loss: 4.141899145852783\n",
      "Epoch: 47, Iteration: 1/2, Loss: 4.139320187180682\n",
      "Epoch: 48, Iteration: 1/2, Loss: 4.140661967278425\n",
      "Epoch: 49, Iteration: 1/2, Loss: 4.135884390947258\n",
      "Epoch: 50, Iteration: 1/2, Loss: 4.135989477681337\n",
      "Epoch: 51, Iteration: 1/2, Loss: 4.130524448076709\n",
      "Epoch: 52, Iteration: 1/2, Loss: 4.124514056247381\n",
      "Epoch: 53, Iteration: 1/2, Loss: 4.129834255718289\n",
      "Epoch: 54, Iteration: 1/2, Loss: 4.123452242110769\n",
      "Epoch: 55, Iteration: 1/2, Loss: 4.119388797298397\n",
      "Epoch: 56, Iteration: 1/2, Loss: 4.1098007941254595\n",
      "Epoch: 57, Iteration: 1/2, Loss: 4.099491808855688\n",
      "Epoch: 58, Iteration: 1/2, Loss: 4.0928001295089675\n",
      "Epoch: 59, Iteration: 1/2, Loss: 4.110315664006476\n",
      "Epoch: 60, Iteration: 1/2, Loss: 4.073458458480415\n",
      "Epoch: 61, Iteration: 1/2, Loss: 4.085883738272083\n",
      "Epoch: 62, Iteration: 1/2, Loss: 4.056579404344829\n",
      "Epoch: 63, Iteration: 1/2, Loss: 4.061926811872292\n",
      "Epoch: 64, Iteration: 1/2, Loss: 4.04934629597106\n",
      "Epoch: 65, Iteration: 1/2, Loss: 4.04745479461314\n",
      "Epoch: 66, Iteration: 1/2, Loss: 3.9932034613392187\n",
      "Epoch: 67, Iteration: 1/2, Loss: 4.004597898660863\n",
      "Epoch: 68, Iteration: 1/2, Loss: 3.9994593498570725\n",
      "Epoch: 69, Iteration: 1/2, Loss: 3.9551098935896043\n",
      "Epoch: 70, Iteration: 1/2, Loss: 3.9090823461515454\n",
      "Epoch: 71, Iteration: 1/2, Loss: 3.926962203540249\n",
      "Epoch: 72, Iteration: 1/2, Loss: 3.8960515206905244\n",
      "Epoch: 73, Iteration: 1/2, Loss: 3.8951744621722586\n",
      "Epoch: 74, Iteration: 1/2, Loss: 3.8452679286944584\n",
      "Epoch: 75, Iteration: 1/2, Loss: 3.7694965225804093\n",
      "Epoch: 76, Iteration: 1/2, Loss: 3.7889888234975375\n",
      "Epoch: 77, Iteration: 1/2, Loss: 3.7111766460783286\n",
      "Epoch: 78, Iteration: 1/2, Loss: 3.690883560482503\n",
      "Epoch: 79, Iteration: 1/2, Loss: 3.6243270560326133\n",
      "Epoch: 80, Iteration: 1/2, Loss: 3.686009735564455\n",
      "Epoch: 81, Iteration: 1/2, Loss: 3.5465040284814613\n",
      "Epoch: 82, Iteration: 1/2, Loss: 3.4945784740665196\n",
      "Epoch: 83, Iteration: 1/2, Loss: 3.4668437389188127\n",
      "Epoch: 84, Iteration: 1/2, Loss: 3.380327990874633\n",
      "Epoch: 85, Iteration: 1/2, Loss: 3.3679154502606954\n",
      "Epoch: 86, Iteration: 1/2, Loss: 3.385470191727647\n",
      "Epoch: 87, Iteration: 1/2, Loss: 3.312087053695974\n",
      "Epoch: 88, Iteration: 1/2, Loss: 3.221278223981358\n",
      "Epoch: 89, Iteration: 1/2, Loss: 3.15864199665757\n",
      "Epoch: 90, Iteration: 1/2, Loss: 2.9979351699559507\n",
      "Epoch: 91, Iteration: 1/2, Loss: 3.1255207720665017\n",
      "Epoch: 92, Iteration: 1/2, Loss: 3.122784517613492\n",
      "Epoch: 93, Iteration: 1/2, Loss: 2.9728719217005706\n",
      "Epoch: 94, Iteration: 1/2, Loss: 2.7195506261296405\n",
      "Epoch: 95, Iteration: 1/2, Loss: 2.9730127945199776\n",
      "Epoch: 96, Iteration: 1/2, Loss: 2.8393913863774025\n",
      "Epoch: 97, Iteration: 1/2, Loss: 2.8060798149129105\n",
      "Epoch: 98, Iteration: 1/2, Loss: 2.733581090222976\n",
      "Epoch: 99, Iteration: 1/2, Loss: 2.8840255219351114\n",
      "Epoch: 100, Iteration: 1/2, Loss: 2.518521514717686\n",
      "Epoch: 101, Iteration: 1/2, Loss: 2.7155606552821236\n",
      "Epoch: 102, Iteration: 1/2, Loss: 2.4847219296382237\n",
      "Epoch: 103, Iteration: 1/2, Loss: 2.593423671241715\n",
      "Epoch: 104, Iteration: 1/2, Loss: 2.5328122309771826\n",
      "Epoch: 105, Iteration: 1/2, Loss: 2.366691387421686\n",
      "Epoch: 106, Iteration: 1/2, Loss: 2.4494889019645254\n",
      "Epoch: 107, Iteration: 1/2, Loss: 2.5027600654362923\n",
      "Epoch: 108, Iteration: 1/2, Loss: 2.4332533990605008\n",
      "Epoch: 109, Iteration: 1/2, Loss: 2.240340103481828\n",
      "Epoch: 110, Iteration: 1/2, Loss: 2.3325117929011823\n",
      "Epoch: 111, Iteration: 1/2, Loss: 2.3213062621803386\n",
      "Epoch: 112, Iteration: 1/2, Loss: 2.13791994463933\n",
      "Epoch: 113, Iteration: 1/2, Loss: 2.260225505531633\n",
      "Epoch: 114, Iteration: 1/2, Loss: 2.128046026838994\n",
      "Epoch: 115, Iteration: 1/2, Loss: 2.1037356065674437\n",
      "Epoch: 116, Iteration: 1/2, Loss: 2.2249727022339885\n",
      "Epoch: 117, Iteration: 1/2, Loss: 2.1218960076250966\n",
      "Epoch: 118, Iteration: 1/2, Loss: 1.999877875776999\n",
      "Epoch: 119, Iteration: 1/2, Loss: 2.0462182055057454\n",
      "Epoch: 120, Iteration: 1/2, Loss: 2.0293843674592003\n",
      "Epoch: 121, Iteration: 1/2, Loss: 2.0142184862452326\n",
      "Epoch: 122, Iteration: 1/2, Loss: 1.9708611903974333\n",
      "Epoch: 123, Iteration: 1/2, Loss: 1.9538288940715538\n",
      "Epoch: 124, Iteration: 1/2, Loss: 1.9491136886973592\n",
      "Epoch: 125, Iteration: 1/2, Loss: 1.884858146530229\n",
      "Epoch: 126, Iteration: 1/2, Loss: 1.9137787826101973\n",
      "Epoch: 127, Iteration: 1/2, Loss: 1.9105756036765804\n",
      "Epoch: 128, Iteration: 1/2, Loss: 1.8672720471384765\n",
      "Epoch: 129, Iteration: 1/2, Loss: 1.823686059529908\n",
      "Epoch: 130, Iteration: 1/2, Loss: 1.841391553236024\n",
      "Epoch: 131, Iteration: 1/2, Loss: 1.8179673624094512\n",
      "Epoch: 132, Iteration: 1/2, Loss: 1.8310026268361157\n",
      "Epoch: 133, Iteration: 1/2, Loss: 1.7666481411422297\n",
      "Epoch: 134, Iteration: 1/2, Loss: 1.777471325041583\n",
      "Epoch: 135, Iteration: 1/2, Loss: 1.7853156660283573\n",
      "Epoch: 136, Iteration: 1/2, Loss: 1.71989573097586\n",
      "Epoch: 137, Iteration: 1/2, Loss: 1.7198182924755179\n",
      "Epoch: 138, Iteration: 1/2, Loss: 1.723127589935132\n",
      "Epoch: 139, Iteration: 1/2, Loss: 1.7455427954100435\n",
      "Epoch: 140, Iteration: 1/2, Loss: 1.716802190874867\n",
      "Epoch: 141, Iteration: 1/2, Loss: 1.682434244552788\n",
      "Epoch: 142, Iteration: 1/2, Loss: 1.666021965902142\n",
      "Epoch: 143, Iteration: 1/2, Loss: 1.7039567501508728\n",
      "Epoch: 144, Iteration: 1/2, Loss: 1.6794131468773223\n",
      "Epoch: 145, Iteration: 1/2, Loss: 1.6448867579101942\n",
      "Epoch: 146, Iteration: 1/2, Loss: 1.6461345182600526\n",
      "Epoch: 147, Iteration: 1/2, Loss: 1.6335290728162288\n",
      "Epoch: 148, Iteration: 1/2, Loss: 1.6411746855402098\n",
      "Epoch: 149, Iteration: 1/2, Loss: 1.633306393330964\n",
      "Epoch: 150, Iteration: 1/2, Loss: 1.6253202023126514\n",
      "Epoch: 151, Iteration: 1/2, Loss: 1.590525902953371\n",
      "Epoch: 152, Iteration: 1/2, Loss: 1.6107838405846686\n",
      "Epoch: 153, Iteration: 1/2, Loss: 1.6331456208731185\n",
      "Epoch: 154, Iteration: 1/2, Loss: 1.5857047309052636\n",
      "Epoch: 155, Iteration: 1/2, Loss: 1.5715671228712162\n",
      "Epoch: 156, Iteration: 1/2, Loss: 1.5855528342675065\n",
      "Epoch: 157, Iteration: 1/2, Loss: 1.5677991323949643\n",
      "Epoch: 158, Iteration: 1/2, Loss: 1.5920179504774046\n",
      "Epoch: 159, Iteration: 1/2, Loss: 1.5587070203284705\n",
      "Epoch: 160, Iteration: 1/2, Loss: 1.5657819652574834\n",
      "Epoch: 161, Iteration: 1/2, Loss: 1.5613231228082785\n",
      "Epoch: 162, Iteration: 1/2, Loss: 1.5692505344222867\n",
      "Epoch: 163, Iteration: 1/2, Loss: 1.5640199882984667\n",
      "Epoch: 164, Iteration: 1/2, Loss: 1.5356458092596044\n",
      "Epoch: 165, Iteration: 1/2, Loss: 1.5309807183980708\n",
      "Epoch: 166, Iteration: 1/2, Loss: 1.5604545266442242\n",
      "Epoch: 167, Iteration: 1/2, Loss: 1.5355105459994633\n",
      "Epoch: 168, Iteration: 1/2, Loss: 1.542165457589629\n",
      "Epoch: 169, Iteration: 1/2, Loss: 1.5224625844219397\n",
      "Epoch: 170, Iteration: 1/2, Loss: 1.5110790085705144\n",
      "Epoch: 171, Iteration: 1/2, Loss: 1.5276025546414091\n",
      "Epoch: 172, Iteration: 1/2, Loss: 1.5481212421802897\n",
      "Epoch: 173, Iteration: 1/2, Loss: 1.5015459958907709\n",
      "Epoch: 174, Iteration: 1/2, Loss: 1.5040622282470197\n",
      "Epoch: 175, Iteration: 1/2, Loss: 1.5250627870103746\n",
      "Epoch: 176, Iteration: 1/2, Loss: 1.5257392687829128\n",
      "Epoch: 177, Iteration: 1/2, Loss: 1.5041646243417792\n",
      "Epoch: 178, Iteration: 1/2, Loss: 1.49406181384584\n",
      "Epoch: 179, Iteration: 1/2, Loss: 1.4954087873753852\n",
      "Epoch: 180, Iteration: 1/2, Loss: 1.501033702964894\n",
      "Epoch: 181, Iteration: 1/2, Loss: 1.5050512083872438\n",
      "Epoch: 182, Iteration: 1/2, Loss: 1.5023983235153207\n",
      "Epoch: 183, Iteration: 1/2, Loss: 1.4914185370580815\n",
      "Epoch: 184, Iteration: 1/2, Loss: 1.4890257899053845\n",
      "Epoch: 185, Iteration: 1/2, Loss: 1.4911602817984495\n",
      "Epoch: 186, Iteration: 1/2, Loss: 1.4873732691916886\n",
      "Epoch: 187, Iteration: 1/2, Loss: 1.4917857734176576\n",
      "Epoch: 188, Iteration: 1/2, Loss: 1.480108839162491\n",
      "Epoch: 189, Iteration: 1/2, Loss: 1.4841504860237695\n",
      "Epoch: 190, Iteration: 1/2, Loss: 1.4817150987167285\n",
      "Epoch: 191, Iteration: 1/2, Loss: 1.4778949874613434\n",
      "Epoch: 192, Iteration: 1/2, Loss: 1.4877992138122904\n",
      "Epoch: 193, Iteration: 1/2, Loss: 1.4675213789675918\n",
      "Epoch: 194, Iteration: 1/2, Loss: 1.4752959204037404\n",
      "Epoch: 195, Iteration: 1/2, Loss: 1.4830058436545628\n",
      "Epoch: 196, Iteration: 1/2, Loss: 1.4636229053994656\n",
      "Epoch: 197, Iteration: 1/2, Loss: 1.4791420138868907\n",
      "Epoch: 198, Iteration: 1/2, Loss: 1.4693232137859267\n",
      "Epoch: 199, Iteration: 1/2, Loss: 1.4685415538510163\n",
      "Epoch: 200, Iteration: 1/2, Loss: 1.4666908393258904\n",
      "Epoch: 201, Iteration: 1/2, Loss: 1.4508648007148768\n",
      "Epoch: 202, Iteration: 1/2, Loss: 1.4707028031212914\n",
      "Epoch: 203, Iteration: 1/2, Loss: 1.4691331208675218\n",
      "Epoch: 204, Iteration: 1/2, Loss: 1.458107682226167\n",
      "Epoch: 205, Iteration: 1/2, Loss: 1.4593355299685162\n",
      "Epoch: 206, Iteration: 1/2, Loss: 1.4590410631524504\n",
      "Epoch: 207, Iteration: 1/2, Loss: 1.4518485588630679\n",
      "Epoch: 208, Iteration: 1/2, Loss: 1.4642001084582428\n",
      "Epoch: 209, Iteration: 1/2, Loss: 1.455889120921962\n",
      "Epoch: 210, Iteration: 1/2, Loss: 1.4568439636433865\n",
      "Epoch: 211, Iteration: 1/2, Loss: 1.4545581657803943\n",
      "Epoch: 212, Iteration: 1/2, Loss: 1.4603052808150783\n",
      "Epoch: 213, Iteration: 1/2, Loss: 1.4522388844488425\n",
      "Epoch: 214, Iteration: 1/2, Loss: 1.4518405688176383\n",
      "Epoch: 215, Iteration: 1/2, Loss: 1.4467793497192794\n",
      "Epoch: 216, Iteration: 1/2, Loss: 1.4535218795087375\n",
      "Epoch: 217, Iteration: 1/2, Loss: 1.4384219090084718\n",
      "Epoch: 218, Iteration: 1/2, Loss: 1.4530265904567834\n",
      "Epoch: 219, Iteration: 1/2, Loss: 1.448049927129719\n",
      "Epoch: 220, Iteration: 1/2, Loss: 1.4464556308945602\n",
      "Epoch: 221, Iteration: 1/2, Loss: 1.4473670590678678\n",
      "Epoch: 222, Iteration: 1/2, Loss: 1.4396698724284014\n",
      "Epoch: 223, Iteration: 1/2, Loss: 1.4510569685753705\n",
      "Epoch: 224, Iteration: 1/2, Loss: 1.4425363584947\n",
      "Epoch: 225, Iteration: 1/2, Loss: 1.4394863443246149\n",
      "Epoch: 226, Iteration: 1/2, Loss: 1.441687155621831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████▎                    | 442/1000 [00:00<00:00, 1043.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 227, Iteration: 1/2, Loss: 1.4469367643334015\n",
      "Epoch: 228, Iteration: 1/2, Loss: 1.4403495963599429\n",
      "Epoch: 229, Iteration: 1/2, Loss: 1.4361199387239996\n",
      "Epoch: 230, Iteration: 1/2, Loss: 1.4496600523249263\n",
      "Epoch: 231, Iteration: 1/2, Loss: 1.4386090541706973\n",
      "Epoch: 232, Iteration: 1/2, Loss: 1.4306327471995144\n",
      "Epoch: 233, Iteration: 1/2, Loss: 1.442144726730592\n",
      "Epoch: 234, Iteration: 1/2, Loss: 1.4333937922072806\n",
      "Epoch: 235, Iteration: 1/2, Loss: 1.4413048274017162\n",
      "Epoch: 236, Iteration: 1/2, Loss: 1.43547299879175\n",
      "Epoch: 237, Iteration: 1/2, Loss: 1.4314813249948386\n",
      "Epoch: 238, Iteration: 1/2, Loss: 1.438875473428746\n",
      "Epoch: 239, Iteration: 1/2, Loss: 1.4347587691609869\n",
      "Epoch: 240, Iteration: 1/2, Loss: 1.4305633303794516\n",
      "Epoch: 241, Iteration: 1/2, Loss: 1.4418961591142736\n",
      "Epoch: 242, Iteration: 1/2, Loss: 1.4282407025830712\n",
      "Epoch: 243, Iteration: 1/2, Loss: 1.4367053196506463\n",
      "Epoch: 244, Iteration: 1/2, Loss: 1.4293349936969477\n",
      "Epoch: 245, Iteration: 1/2, Loss: 1.4314469908919647\n",
      "Epoch: 246, Iteration: 1/2, Loss: 1.4272894620258043\n",
      "Epoch: 247, Iteration: 1/2, Loss: 1.437938426919188\n",
      "Epoch: 248, Iteration: 1/2, Loss: 1.430225515055271\n",
      "Epoch: 249, Iteration: 1/2, Loss: 1.4298907654574098\n",
      "Epoch: 250, Iteration: 1/2, Loss: 1.425443618420617\n",
      "Epoch: 251, Iteration: 1/2, Loss: 1.4283693741139771\n",
      "Epoch: 252, Iteration: 1/2, Loss: 1.432737397611288\n",
      "Epoch: 253, Iteration: 1/2, Loss: 1.424343624069334\n",
      "Epoch: 254, Iteration: 1/2, Loss: 1.431330137241304\n",
      "Epoch: 255, Iteration: 1/2, Loss: 1.423207903334639\n",
      "Epoch: 256, Iteration: 1/2, Loss: 1.4280098319430883\n",
      "Epoch: 257, Iteration: 1/2, Loss: 1.4293281837299832\n",
      "Epoch: 258, Iteration: 1/2, Loss: 1.4192515435014492\n",
      "Epoch: 259, Iteration: 1/2, Loss: 1.4287892318355184\n",
      "Epoch: 260, Iteration: 1/2, Loss: 1.425315740826629\n",
      "Epoch: 261, Iteration: 1/2, Loss: 1.4255197621229336\n",
      "Epoch: 262, Iteration: 1/2, Loss: 1.424718250428319\n",
      "Epoch: 263, Iteration: 1/2, Loss: 1.4210447842758858\n",
      "Epoch: 264, Iteration: 1/2, Loss: 1.4305008242933428\n",
      "Epoch: 265, Iteration: 1/2, Loss: 1.4235558713312835\n",
      "Epoch: 266, Iteration: 1/2, Loss: 1.4201501910609398\n",
      "Epoch: 267, Iteration: 1/2, Loss: 1.423424567504409\n",
      "Epoch: 268, Iteration: 1/2, Loss: 1.425282813682849\n",
      "Epoch: 269, Iteration: 1/2, Loss: 1.419323842850929\n",
      "Epoch: 270, Iteration: 1/2, Loss: 1.4215520067001708\n",
      "Epoch: 271, Iteration: 1/2, Loss: 1.422592557900025\n",
      "Epoch: 272, Iteration: 1/2, Loss: 1.420448949240643\n",
      "Epoch: 273, Iteration: 1/2, Loss: 1.4214865281793654\n",
      "Epoch: 274, Iteration: 1/2, Loss: 1.4237541235625282\n",
      "Epoch: 275, Iteration: 1/2, Loss: 1.4176987233247447\n",
      "Epoch: 276, Iteration: 1/2, Loss: 1.4200979347343097\n",
      "Epoch: 277, Iteration: 1/2, Loss: 1.4200164895880965\n",
      "Epoch: 278, Iteration: 1/2, Loss: 1.419726655623112\n",
      "Epoch: 279, Iteration: 1/2, Loss: 1.4193127621638713\n",
      "Epoch: 280, Iteration: 1/2, Loss: 1.4192151786104708\n",
      "Epoch: 281, Iteration: 1/2, Loss: 1.418715395962669\n",
      "Epoch: 282, Iteration: 1/2, Loss: 1.421285936411134\n",
      "Epoch: 283, Iteration: 1/2, Loss: 1.4183866392036228\n",
      "Epoch: 284, Iteration: 1/2, Loss: 1.418028088247571\n",
      "Epoch: 285, Iteration: 1/2, Loss: 1.4148692272605783\n",
      "Epoch: 286, Iteration: 1/2, Loss: 1.41542693062614\n",
      "Epoch: 287, Iteration: 1/2, Loss: 1.4176429386306677\n",
      "Epoch: 288, Iteration: 1/2, Loss: 1.4217840693496315\n",
      "Epoch: 289, Iteration: 1/2, Loss: 1.4168718057282061\n",
      "Epoch: 290, Iteration: 1/2, Loss: 1.4140689206586767\n",
      "Epoch: 291, Iteration: 1/2, Loss: 1.4165633845616363\n",
      "Epoch: 292, Iteration: 1/2, Loss: 1.4157874009615472\n",
      "Epoch: 293, Iteration: 1/2, Loss: 1.4159367652330856\n",
      "Epoch: 294, Iteration: 1/2, Loss: 1.4183148066406424\n",
      "Epoch: 295, Iteration: 1/2, Loss: 1.4135295215325527\n",
      "Epoch: 296, Iteration: 1/2, Loss: 1.4152576558356262\n",
      "Epoch: 297, Iteration: 1/2, Loss: 1.416977126096874\n",
      "Epoch: 298, Iteration: 1/2, Loss: 1.4103282810626951\n",
      "Epoch: 299, Iteration: 1/2, Loss: 1.4192198708561388\n",
      "Epoch: 300, Iteration: 1/2, Loss: 1.4124599701800473\n",
      "Epoch: 301, Iteration: 1/2, Loss: 1.4119117790581397\n",
      "Epoch: 302, Iteration: 1/2, Loss: 1.4163420804201428\n",
      "Epoch: 303, Iteration: 1/2, Loss: 1.4113312055279423\n",
      "Epoch: 304, Iteration: 1/2, Loss: 1.4161233370059845\n",
      "Epoch: 305, Iteration: 1/2, Loss: 1.4131382310623288\n",
      "Epoch: 306, Iteration: 1/2, Loss: 1.4129430073123737\n",
      "Epoch: 307, Iteration: 1/2, Loss: 1.4135961847921343\n",
      "Epoch: 308, Iteration: 1/2, Loss: 1.414732980968694\n",
      "Epoch: 309, Iteration: 1/2, Loss: 1.4106321751200497\n",
      "Epoch: 310, Iteration: 1/2, Loss: 1.4124124514760434\n",
      "Epoch: 311, Iteration: 1/2, Loss: 1.4124620898221667\n",
      "Epoch: 312, Iteration: 1/2, Loss: 1.4103451901481865\n",
      "Epoch: 313, Iteration: 1/2, Loss: 1.4135011983750925\n",
      "Epoch: 314, Iteration: 1/2, Loss: 1.4141828287812965\n",
      "Epoch: 315, Iteration: 1/2, Loss: 1.411521078168111\n",
      "Epoch: 316, Iteration: 1/2, Loss: 1.4077914958678206\n",
      "Epoch: 317, Iteration: 1/2, Loss: 1.4148054792852631\n",
      "Epoch: 318, Iteration: 1/2, Loss: 1.4095830945302292\n",
      "Epoch: 319, Iteration: 1/2, Loss: 1.411096599313654\n",
      "Epoch: 320, Iteration: 1/2, Loss: 1.410541714205667\n",
      "Epoch: 321, Iteration: 1/2, Loss: 1.4109487096889406\n",
      "Epoch: 322, Iteration: 1/2, Loss: 1.4100955664238952\n",
      "Epoch: 323, Iteration: 1/2, Loss: 1.4104826202182965\n",
      "Epoch: 324, Iteration: 1/2, Loss: 1.4100716732231633\n",
      "Epoch: 325, Iteration: 1/2, Loss: 1.410176274023696\n",
      "Epoch: 326, Iteration: 1/2, Loss: 1.4098845536496958\n",
      "Epoch: 327, Iteration: 1/2, Loss: 1.409881048170004\n",
      "Epoch: 328, Iteration: 1/2, Loss: 1.4094788781083385\n",
      "Epoch: 329, Iteration: 1/2, Loss: 1.4093219043739957\n",
      "Epoch: 330, Iteration: 1/2, Loss: 1.4094484358885904\n",
      "Epoch: 331, Iteration: 1/2, Loss: 1.4094395290683608\n",
      "Epoch: 332, Iteration: 1/2, Loss: 1.4072014966486894\n",
      "Epoch: 333, Iteration: 1/2, Loss: 1.410325760767753\n",
      "Epoch: 334, Iteration: 1/2, Loss: 1.4106846120718\n",
      "Epoch: 335, Iteration: 1/2, Loss: 1.4051629814227078\n",
      "Epoch: 336, Iteration: 1/2, Loss: 1.4098890722835884\n",
      "Epoch: 337, Iteration: 1/2, Loss: 1.410374212300505\n",
      "Epoch: 338, Iteration: 1/2, Loss: 1.4082123468966659\n",
      "Epoch: 339, Iteration: 1/2, Loss: 1.4065935772022469\n",
      "Epoch: 340, Iteration: 1/2, Loss: 1.4078129370614034\n",
      "Epoch: 341, Iteration: 1/2, Loss: 1.4061536402024024\n",
      "Epoch: 342, Iteration: 1/2, Loss: 1.4090503378675288\n",
      "Epoch: 343, Iteration: 1/2, Loss: 1.4062627823044274\n",
      "Epoch: 344, Iteration: 1/2, Loss: 1.4074594558565714\n",
      "Epoch: 345, Iteration: 1/2, Loss: 1.4073711165823497\n",
      "Epoch: 346, Iteration: 1/2, Loss: 1.4087470524175694\n",
      "Epoch: 347, Iteration: 1/2, Loss: 1.406964140269733\n",
      "Epoch: 348, Iteration: 1/2, Loss: 1.4086250468642647\n",
      "Epoch: 349, Iteration: 1/2, Loss: 1.405268236504158\n",
      "Epoch: 350, Iteration: 1/2, Loss: 1.4068347194446933\n",
      "Epoch: 351, Iteration: 1/2, Loss: 1.4066358675766613\n",
      "Epoch: 352, Iteration: 1/2, Loss: 1.405049061448226\n",
      "Epoch: 353, Iteration: 1/2, Loss: 1.4093164860772849\n",
      "Epoch: 354, Iteration: 1/2, Loss: 1.4062900124294924\n",
      "Epoch: 355, Iteration: 1/2, Loss: 1.4048940533794387\n",
      "Epoch: 356, Iteration: 1/2, Loss: 1.406076249978347\n",
      "Epoch: 357, Iteration: 1/2, Loss: 1.405692507000223\n",
      "Epoch: 358, Iteration: 1/2, Loss: 1.404451339719588\n",
      "Epoch: 359, Iteration: 1/2, Loss: 1.4075050852215614\n",
      "Epoch: 360, Iteration: 1/2, Loss: 1.4068055520065634\n",
      "Epoch: 361, Iteration: 1/2, Loss: 1.4040444814959747\n",
      "Epoch: 362, Iteration: 1/2, Loss: 1.4056439270273013\n",
      "Epoch: 363, Iteration: 1/2, Loss: 1.4053366396983042\n",
      "Epoch: 364, Iteration: 1/2, Loss: 1.4038145406683644\n",
      "Epoch: 365, Iteration: 1/2, Loss: 1.4064968465744436\n",
      "Epoch: 366, Iteration: 1/2, Loss: 1.4052618483088297\n",
      "Epoch: 367, Iteration: 1/2, Loss: 1.4060537587239215\n",
      "Epoch: 368, Iteration: 1/2, Loss: 1.4048154277811455\n",
      "Epoch: 369, Iteration: 1/2, Loss: 1.4033185258397052\n",
      "Epoch: 370, Iteration: 1/2, Loss: 1.406069547243325\n",
      "Epoch: 371, Iteration: 1/2, Loss: 1.4045013890316618\n",
      "Epoch: 372, Iteration: 1/2, Loss: 1.4032228885553857\n",
      "Epoch: 373, Iteration: 1/2, Loss: 1.4043908906581648\n",
      "Epoch: 374, Iteration: 1/2, Loss: 1.4030102522952834\n",
      "Epoch: 375, Iteration: 1/2, Loss: 1.4054648593911303\n",
      "Epoch: 376, Iteration: 1/2, Loss: 1.4042371382192766\n",
      "Epoch: 377, Iteration: 1/2, Loss: 1.4038735169358671\n",
      "Epoch: 378, Iteration: 1/2, Loss: 1.4026787126210296\n",
      "Epoch: 379, Iteration: 1/2, Loss: 1.404898602582545\n",
      "Epoch: 380, Iteration: 1/2, Loss: 1.404055842985318\n",
      "Epoch: 381, Iteration: 1/2, Loss: 1.4033174224631126\n",
      "Epoch: 382, Iteration: 1/2, Loss: 1.4026306576193608\n",
      "Epoch: 383, Iteration: 1/2, Loss: 1.4046385165996116\n",
      "Epoch: 384, Iteration: 1/2, Loss: 1.4032336969218027\n",
      "Epoch: 385, Iteration: 1/2, Loss: 1.4034537514891108\n",
      "Epoch: 386, Iteration: 1/2, Loss: 1.4031020955832165\n",
      "Epoch: 387, Iteration: 1/2, Loss: 1.4033538429002579\n",
      "Epoch: 388, Iteration: 1/2, Loss: 1.4029053974999246\n",
      "Epoch: 389, Iteration: 1/2, Loss: 1.401970663072326\n",
      "Epoch: 390, Iteration: 1/2, Loss: 1.4029256486430994\n",
      "Epoch: 391, Iteration: 1/2, Loss: 1.402710779771632\n",
      "Epoch: 392, Iteration: 1/2, Loss: 1.402766195070671\n",
      "Epoch: 393, Iteration: 1/2, Loss: 1.40398511208587\n",
      "Epoch: 394, Iteration: 1/2, Loss: 1.4036744859361625\n",
      "Epoch: 395, Iteration: 1/2, Loss: 1.4026890329821415\n",
      "Epoch: 396, Iteration: 1/2, Loss: 1.4012251305622738\n",
      "Epoch: 397, Iteration: 1/2, Loss: 1.403590610654922\n",
      "Epoch: 398, Iteration: 1/2, Loss: 1.4009217879574165\n",
      "Epoch: 399, Iteration: 1/2, Loss: 1.4011306630663376\n",
      "Epoch: 400, Iteration: 1/2, Loss: 1.403368615483993\n",
      "Epoch: 401, Iteration: 1/2, Loss: 1.4021320642980573\n",
      "Epoch: 402, Iteration: 1/2, Loss: 1.401959584613801\n",
      "Epoch: 403, Iteration: 1/2, Loss: 1.4019243086568318\n",
      "Epoch: 404, Iteration: 1/2, Loss: 1.4018981530420742\n",
      "Epoch: 405, Iteration: 1/2, Loss: 1.4016170730885995\n",
      "Epoch: 406, Iteration: 1/2, Loss: 1.4020459105469827\n",
      "Epoch: 407, Iteration: 1/2, Loss: 1.4015254067084713\n",
      "Epoch: 408, Iteration: 1/2, Loss: 1.4017269591983332\n",
      "Epoch: 409, Iteration: 1/2, Loss: 1.4023932447820502\n",
      "Epoch: 410, Iteration: 1/2, Loss: 1.4005978276196043\n",
      "Epoch: 411, Iteration: 1/2, Loss: 1.4012697915646424\n",
      "Epoch: 412, Iteration: 1/2, Loss: 1.4024449158782795\n",
      "Epoch: 413, Iteration: 1/2, Loss: 1.399116681064097\n",
      "Epoch: 414, Iteration: 1/2, Loss: 1.4011655419612365\n",
      "Epoch: 415, Iteration: 1/2, Loss: 1.4021317061791456\n",
      "Epoch: 416, Iteration: 1/2, Loss: 1.402068661669428\n",
      "Epoch: 417, Iteration: 1/2, Loss: 1.3998602348570066\n",
      "Epoch: 418, Iteration: 1/2, Loss: 1.400119068060743\n",
      "Epoch: 419, Iteration: 1/2, Loss: 1.401958197490647\n",
      "Epoch: 420, Iteration: 1/2, Loss: 1.39969608705527\n",
      "Epoch: 421, Iteration: 1/2, Loss: 1.4007917367465899\n",
      "Epoch: 422, Iteration: 1/2, Loss: 1.4014559108264582\n",
      "Epoch: 423, Iteration: 1/2, Loss: 1.401759735095668\n",
      "Epoch: 424, Iteration: 1/2, Loss: 1.3986762123511416\n",
      "Epoch: 425, Iteration: 1/2, Loss: 1.4015669551613943\n",
      "Epoch: 426, Iteration: 1/2, Loss: 1.4003095032176407\n",
      "Epoch: 427, Iteration: 1/2, Loss: 1.4002546639147306\n",
      "Epoch: 428, Iteration: 1/2, Loss: 1.4003251144866216\n",
      "Epoch: 429, Iteration: 1/2, Loss: 1.4005292922115635\n",
      "Epoch: 430, Iteration: 1/2, Loss: 1.3991488081748114\n",
      "Epoch: 431, Iteration: 1/2, Loss: 1.400924096194352\n",
      "Epoch: 432, Iteration: 1/2, Loss: 1.4002604699220011\n",
      "Epoch: 433, Iteration: 1/2, Loss: 1.40017450478078\n",
      "Epoch: 434, Iteration: 1/2, Loss: 1.4008977707259809\n",
      "Epoch: 435, Iteration: 1/2, Loss: 1.3997606931541127\n",
      "Epoch: 436, Iteration: 1/2, Loss: 1.3979678943052558\n",
      "Epoch: 437, Iteration: 1/2, Loss: 1.400979154776913\n",
      "Epoch: 438, Iteration: 1/2, Loss: 1.4006620773605931\n",
      "Epoch: 439, Iteration: 1/2, Loss: 1.3978235869043485\n",
      "Epoch: 440, Iteration: 1/2, Loss: 1.4014091219717\n",
      "Epoch: 441, Iteration: 1/2, Loss: 1.398876822265204\n",
      "Epoch: 442, Iteration: 1/2, Loss: 1.3992640745769913\n",
      "Epoch: 443, Iteration: 1/2, Loss: 1.398625512180589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████                | 569/1000 [00:00<00:00, 1102.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 444, Iteration: 1/2, Loss: 1.4003212296153915\n",
      "Epoch: 445, Iteration: 1/2, Loss: 1.3995159959779992\n",
      "Epoch: 446, Iteration: 1/2, Loss: 1.3992226701432355\n",
      "Epoch: 447, Iteration: 1/2, Loss: 1.399302804770735\n",
      "Epoch: 448, Iteration: 1/2, Loss: 1.398538749939086\n",
      "Epoch: 449, Iteration: 1/2, Loss: 1.4000221396456989\n",
      "Epoch: 450, Iteration: 1/2, Loss: 1.3999769004761276\n",
      "Epoch: 451, Iteration: 1/2, Loss: 1.3974299427173915\n",
      "Epoch: 452, Iteration: 1/2, Loss: 1.3988982496417022\n",
      "Epoch: 453, Iteration: 1/2, Loss: 1.399832132914614\n",
      "Epoch: 454, Iteration: 1/2, Loss: 1.399222729073459\n",
      "Epoch: 455, Iteration: 1/2, Loss: 1.3995753090891188\n",
      "Epoch: 456, Iteration: 1/2, Loss: 1.3980230844935613\n",
      "Epoch: 457, Iteration: 1/2, Loss: 1.3989165400610486\n",
      "Epoch: 458, Iteration: 1/2, Loss: 1.398492683707643\n",
      "Epoch: 459, Iteration: 1/2, Loss: 1.3988211265122756\n",
      "Epoch: 460, Iteration: 1/2, Loss: 1.3986963641368975\n",
      "Epoch: 461, Iteration: 1/2, Loss: 1.3984889198535218\n",
      "Epoch: 462, Iteration: 1/2, Loss: 1.3985701261056716\n",
      "Epoch: 463, Iteration: 1/2, Loss: 1.3986503669283468\n",
      "Epoch: 464, Iteration: 1/2, Loss: 1.3984797618952998\n",
      "Epoch: 465, Iteration: 1/2, Loss: 1.3992046721033575\n",
      "Epoch: 466, Iteration: 1/2, Loss: 1.3977615472840996\n",
      "Epoch: 467, Iteration: 1/2, Loss: 1.397453642973105\n",
      "Epoch: 468, Iteration: 1/2, Loss: 1.3989240464715973\n",
      "Epoch: 469, Iteration: 1/2, Loss: 1.3983799578762772\n",
      "Epoch: 470, Iteration: 1/2, Loss: 1.3974782169185986\n",
      "Epoch: 471, Iteration: 1/2, Loss: 1.3996414325291966\n",
      "Epoch: 472, Iteration: 1/2, Loss: 1.3973939820994283\n",
      "Epoch: 473, Iteration: 1/2, Loss: 1.3981212249242414\n",
      "Epoch: 474, Iteration: 1/2, Loss: 1.398127999034789\n",
      "Epoch: 475, Iteration: 1/2, Loss: 1.3977535415327285\n",
      "Epoch: 476, Iteration: 1/2, Loss: 1.3981827045301674\n",
      "Epoch: 477, Iteration: 1/2, Loss: 1.3970985204875275\n",
      "Epoch: 478, Iteration: 1/2, Loss: 1.3977218995061937\n",
      "Epoch: 479, Iteration: 1/2, Loss: 1.3995664570803301\n",
      "Epoch: 480, Iteration: 1/2, Loss: 1.3969307033610057\n",
      "Epoch: 481, Iteration: 1/2, Loss: 1.396893603442797\n",
      "Epoch: 482, Iteration: 1/2, Loss: 1.3994253527111842\n",
      "Epoch: 483, Iteration: 1/2, Loss: 1.396682721413882\n",
      "Epoch: 484, Iteration: 1/2, Loss: 1.3977330110168902\n",
      "Epoch: 485, Iteration: 1/2, Loss: 1.3983160499757519\n",
      "Epoch: 486, Iteration: 1/2, Loss: 1.3967695242602138\n",
      "Epoch: 487, Iteration: 1/2, Loss: 1.3969030467269583\n",
      "Epoch: 488, Iteration: 1/2, Loss: 1.398316551120887\n",
      "Epoch: 489, Iteration: 1/2, Loss: 1.397981806644605\n",
      "Epoch: 490, Iteration: 1/2, Loss: 1.396050406720553\n",
      "Epoch: 491, Iteration: 1/2, Loss: 1.3980718412712165\n",
      "Epoch: 492, Iteration: 1/2, Loss: 1.3971562314180446\n",
      "Epoch: 493, Iteration: 1/2, Loss: 1.397536949646896\n",
      "Epoch: 494, Iteration: 1/2, Loss: 1.3979464144939397\n",
      "Epoch: 495, Iteration: 1/2, Loss: 1.3963021856499682\n",
      "Epoch: 496, Iteration: 1/2, Loss: 1.3973013384749646\n",
      "Epoch: 497, Iteration: 1/2, Loss: 1.397194169427418\n",
      "Epoch: 498, Iteration: 1/2, Loss: 1.396889153267036\n",
      "Epoch: 499, Iteration: 1/2, Loss: 1.3963826787943616\n",
      "Epoch: 500, Iteration: 1/2, Loss: 1.3979495452356148\n",
      "Epoch: 501, Iteration: 1/2, Loss: 1.3969019222146037\n",
      "Epoch: 502, Iteration: 1/2, Loss: 1.396933851771161\n",
      "Epoch: 503, Iteration: 1/2, Loss: 1.3970400594969177\n",
      "Epoch: 504, Iteration: 1/2, Loss: 1.3968882547383359\n",
      "Epoch: 505, Iteration: 1/2, Loss: 1.396733101040755\n",
      "Epoch: 506, Iteration: 1/2, Loss: 1.3960395037164415\n",
      "Epoch: 507, Iteration: 1/2, Loss: 1.3976011206873817\n",
      "Epoch: 508, Iteration: 1/2, Loss: 1.3960897123398692\n",
      "Epoch: 509, Iteration: 1/2, Loss: 1.3967197487602285\n",
      "Epoch: 510, Iteration: 1/2, Loss: 1.3966858469681438\n",
      "Epoch: 511, Iteration: 1/2, Loss: 1.398035903123644\n",
      "Epoch: 512, Iteration: 1/2, Loss: 1.3958198645742095\n",
      "Epoch: 513, Iteration: 1/2, Loss: 1.3958466451321898\n",
      "Epoch: 514, Iteration: 1/2, Loss: 1.397396462553246\n",
      "Epoch: 515, Iteration: 1/2, Loss: 1.3963433629032918\n",
      "Epoch: 516, Iteration: 1/2, Loss: 1.3964816477523452\n",
      "Epoch: 517, Iteration: 1/2, Loss: 1.396449164263636\n",
      "Epoch: 518, Iteration: 1/2, Loss: 1.3957523838915855\n",
      "Epoch: 519, Iteration: 1/2, Loss: 1.3972552236036568\n",
      "Epoch: 520, Iteration: 1/2, Loss: 1.3956087748904267\n",
      "Epoch: 521, Iteration: 1/2, Loss: 1.3969506867693005\n",
      "Epoch: 522, Iteration: 1/2, Loss: 1.3970278940338616\n",
      "Epoch: 523, Iteration: 1/2, Loss: 1.3947853107680332\n",
      "Epoch: 524, Iteration: 1/2, Loss: 1.3970465957092868\n",
      "Epoch: 525, Iteration: 1/2, Loss: 1.39622720213083\n",
      "Epoch: 526, Iteration: 1/2, Loss: 1.3959350939477235\n",
      "Epoch: 527, Iteration: 1/2, Loss: 1.3963717643603513\n",
      "Epoch: 528, Iteration: 1/2, Loss: 1.3959577465227138\n",
      "Epoch: 529, Iteration: 1/2, Loss: 1.3960245640663502\n",
      "Epoch: 530, Iteration: 1/2, Loss: 1.396235831401524\n",
      "Epoch: 531, Iteration: 1/2, Loss: 1.396505009635545\n",
      "Epoch: 532, Iteration: 1/2, Loss: 1.3948164645946382\n",
      "Epoch: 533, Iteration: 1/2, Loss: 1.3965583712346508\n",
      "Epoch: 534, Iteration: 1/2, Loss: 1.3960061899913252\n",
      "Epoch: 535, Iteration: 1/2, Loss: 1.3958125312063274\n",
      "Epoch: 536, Iteration: 1/2, Loss: 1.3957582136638789\n",
      "Epoch: 537, Iteration: 1/2, Loss: 1.3958006242581864\n",
      "Epoch: 538, Iteration: 1/2, Loss: 1.3953361168349598\n",
      "Epoch: 539, Iteration: 1/2, Loss: 1.3962592766919926\n",
      "Epoch: 540, Iteration: 1/2, Loss: 1.395973332974497\n",
      "Epoch: 541, Iteration: 1/2, Loss: 1.3961991782134915\n",
      "Epoch: 542, Iteration: 1/2, Loss: 1.3945660851343877\n",
      "Epoch: 543, Iteration: 1/2, Loss: 1.3962908469461675\n",
      "Epoch: 544, Iteration: 1/2, Loss: 1.3961393036050649\n",
      "Epoch: 545, Iteration: 1/2, Loss: 1.3950050308631965\n",
      "Epoch: 546, Iteration: 1/2, Loss: 1.3950414711122678\n",
      "Epoch: 547, Iteration: 1/2, Loss: 1.3961009478830444\n",
      "Epoch: 548, Iteration: 1/2, Loss: 1.3956722491323474\n",
      "Epoch: 549, Iteration: 1/2, Loss: 1.3953187484919436\n",
      "Epoch: 550, Iteration: 1/2, Loss: 1.3955458094833078\n",
      "Epoch: 551, Iteration: 1/2, Loss: 1.3947816392828711\n",
      "Epoch: 552, Iteration: 1/2, Loss: 1.3960201547138316\n",
      "Epoch: 553, Iteration: 1/2, Loss: 1.3954345246855187\n",
      "Epoch: 554, Iteration: 1/2, Loss: 1.395293021095314\n",
      "Epoch: 555, Iteration: 1/2, Loss: 1.3954858242751114\n",
      "Epoch: 556, Iteration: 1/2, Loss: 1.3952848125499593\n",
      "Epoch: 557, Iteration: 1/2, Loss: 1.3952561024870422\n",
      "Epoch: 558, Iteration: 1/2, Loss: 1.3952647169546513\n",
      "Epoch: 559, Iteration: 1/2, Loss: 1.395304480814213\n",
      "Epoch: 560, Iteration: 1/2, Loss: 1.3951098123935293\n",
      "Epoch: 561, Iteration: 1/2, Loss: 1.395906983159723\n",
      "Epoch: 562, Iteration: 1/2, Loss: 1.3940064075847687\n",
      "Epoch: 563, Iteration: 1/2, Loss: 1.3961519814297771\n",
      "Epoch: 564, Iteration: 1/2, Loss: 1.3947139452014945\n",
      "Epoch: 565, Iteration: 1/2, Loss: 1.3950159789584036\n",
      "Epoch: 566, Iteration: 1/2, Loss: 1.3945280688872113\n",
      "Epoch: 567, Iteration: 1/2, Loss: 1.39557349866744\n",
      "Epoch: 568, Iteration: 1/2, Loss: 1.3949107855101843\n",
      "Epoch: 569, Iteration: 1/2, Loss: 1.3950904054930364\n",
      "Epoch: 570, Iteration: 1/2, Loss: 1.3948261526037302\n",
      "Epoch: 571, Iteration: 1/2, Loss: 1.395149136914859\n",
      "Epoch: 572, Iteration: 1/2, Loss: 1.3949169203585843\n",
      "Epoch: 573, Iteration: 1/2, Loss: 1.3948934972282152\n",
      "Epoch: 574, Iteration: 1/2, Loss: 1.3946605639816272\n",
      "Epoch: 575, Iteration: 1/2, Loss: 1.3944277041337414\n",
      "Epoch: 576, Iteration: 1/2, Loss: 1.39541063934153\n",
      "Epoch: 577, Iteration: 1/2, Loss: 1.394765347110697\n",
      "Epoch: 578, Iteration: 1/2, Loss: 1.3947052939250175\n",
      "Epoch: 579, Iteration: 1/2, Loss: 1.394851764806139\n",
      "Epoch: 580, Iteration: 1/2, Loss: 1.3945605150710323\n",
      "Epoch: 581, Iteration: 1/2, Loss: 1.3948421091379464\n",
      "Epoch: 582, Iteration: 1/2, Loss: 1.3947124129144761\n",
      "Epoch: 583, Iteration: 1/2, Loss: 1.3946964867858835\n",
      "Epoch: 584, Iteration: 1/2, Loss: 1.3946376592835161\n",
      "Epoch: 585, Iteration: 1/2, Loss: 1.3940082485528293\n",
      "Epoch: 586, Iteration: 1/2, Loss: 1.394995607277978\n",
      "Epoch: 587, Iteration: 1/2, Loss: 1.394171081952352\n",
      "Epoch: 588, Iteration: 1/2, Loss: 1.394586298543345\n",
      "Epoch: 589, Iteration: 1/2, Loss: 1.394987670889558\n",
      "Epoch: 590, Iteration: 1/2, Loss: 1.3944740235938324\n",
      "Epoch: 591, Iteration: 1/2, Loss: 1.394511768514808\n",
      "Epoch: 592, Iteration: 1/2, Loss: 1.3949593895439163\n",
      "Epoch: 593, Iteration: 1/2, Loss: 1.3938455076700746\n",
      "Epoch: 594, Iteration: 1/2, Loss: 1.394969960913284\n",
      "Epoch: 595, Iteration: 1/2, Loss: 1.3939388837891828\n",
      "Epoch: 596, Iteration: 1/2, Loss: 1.394344667838856\n",
      "Epoch: 597, Iteration: 1/2, Loss: 1.3948711447124222\n",
      "Epoch: 598, Iteration: 1/2, Loss: 1.393849794454328\n",
      "Epoch: 599, Iteration: 1/2, Loss: 1.3942115471562482\n",
      "Epoch: 600, Iteration: 1/2, Loss: 1.3943259222558881\n",
      "Epoch: 601, Iteration: 1/2, Loss: 1.3938843751579948\n",
      "Epoch: 602, Iteration: 1/2, Loss: 1.3947292840891008\n",
      "Epoch: 603, Iteration: 1/2, Loss: 1.3941315704286317\n",
      "Epoch: 604, Iteration: 1/2, Loss: 1.3938263119023073\n",
      "Epoch: 605, Iteration: 1/2, Loss: 1.3945678239628236\n",
      "Epoch: 606, Iteration: 1/2, Loss: 1.3941301538348676\n",
      "Epoch: 607, Iteration: 1/2, Loss: 1.3943393307819674\n",
      "Epoch: 608, Iteration: 1/2, Loss: 1.3935545884400327\n",
      "Epoch: 609, Iteration: 1/2, Loss: 1.3946740202844272\n",
      "Epoch: 610, Iteration: 1/2, Loss: 1.3945535538348415\n",
      "Epoch: 611, Iteration: 1/2, Loss: 1.3935015766952468\n",
      "Epoch: 612, Iteration: 1/2, Loss: 1.3945177692589144\n",
      "Epoch: 613, Iteration: 1/2, Loss: 1.3930921937881462\n",
      "Epoch: 614, Iteration: 1/2, Loss: 1.3944774570316296\n",
      "Epoch: 615, Iteration: 1/2, Loss: 1.39343080486069\n",
      "Epoch: 616, Iteration: 1/2, Loss: 1.394464710831379\n",
      "Epoch: 617, Iteration: 1/2, Loss: 1.3940020672756193\n",
      "Epoch: 618, Iteration: 1/2, Loss: 1.3938968181352442\n",
      "Epoch: 619, Iteration: 1/2, Loss: 1.3943659699085345\n",
      "Epoch: 620, Iteration: 1/2, Loss: 1.3934160096017862\n",
      "Epoch: 621, Iteration: 1/2, Loss: 1.3944726399141647\n",
      "Epoch: 622, Iteration: 1/2, Loss: 1.393213678865914\n",
      "Epoch: 623, Iteration: 1/2, Loss: 1.3934765411141\n",
      "Epoch: 624, Iteration: 1/2, Loss: 1.394267141051185\n",
      "Epoch: 625, Iteration: 1/2, Loss: 1.393803770065085\n",
      "Epoch: 626, Iteration: 1/2, Loss: 1.3943134145305267\n",
      "Epoch: 627, Iteration: 1/2, Loss: 1.3931329699869246\n",
      "Epoch: 628, Iteration: 1/2, Loss: 1.3943669473292797\n",
      "Epoch: 629, Iteration: 1/2, Loss: 1.3931576215835721\n",
      "Epoch: 630, Iteration: 1/2, Loss: 1.3932052140891988\n",
      "Epoch: 631, Iteration: 1/2, Loss: 1.3946631869675477\n",
      "Epoch: 632, Iteration: 1/2, Loss: 1.3927878101574858\n",
      "Epoch: 633, Iteration: 1/2, Loss: 1.3939960189954603\n",
      "Epoch: 634, Iteration: 1/2, Loss: 1.3936960865700874\n",
      "Epoch: 635, Iteration: 1/2, Loss: 1.3940809580730538\n",
      "Epoch: 636, Iteration: 1/2, Loss: 1.3936875665362596\n",
      "Epoch: 637, Iteration: 1/2, Loss: 1.392964268945018\n",
      "Epoch: 638, Iteration: 1/2, Loss: 1.3932252121184687\n",
      "Epoch: 639, Iteration: 1/2, Loss: 1.3940296368716014\n",
      "Epoch: 640, Iteration: 1/2, Loss: 1.3934211777218073\n",
      "Epoch: 641, Iteration: 1/2, Loss: 1.3931703937864741\n",
      "Epoch: 642, Iteration: 1/2, Loss: 1.394311736839051\n",
      "Epoch: 643, Iteration: 1/2, Loss: 1.3934811442002022\n",
      "Epoch: 644, Iteration: 1/2, Loss: 1.3929985971074499\n",
      "Epoch: 645, Iteration: 1/2, Loss: 1.3935646313856669\n",
      "Epoch: 646, Iteration: 1/2, Loss: 1.393719657230036\n",
      "Epoch: 647, Iteration: 1/2, Loss: 1.3935305424167757\n",
      "Epoch: 648, Iteration: 1/2, Loss: 1.3932677931501183\n",
      "Epoch: 649, Iteration: 1/2, Loss: 1.3930422177212987\n",
      "Epoch: 650, Iteration: 1/2, Loss: 1.3933970452825566\n",
      "Epoch: 651, Iteration: 1/2, Loss: 1.393159038874686\n",
      "Epoch: 652, Iteration: 1/2, Loss: 1.3937959236723556\n",
      "Epoch: 653, Iteration: 1/2, Loss: 1.3925103666139942\n",
      "Epoch: 654, Iteration: 1/2, Loss: 1.3932992585571027\n",
      "Epoch: 655, Iteration: 1/2, Loss: 1.3936574048240815\n",
      "Epoch: 656, Iteration: 1/2, Loss: 1.3932933229923348\n",
      "Epoch: 657, Iteration: 1/2, Loss: 1.3933241521533146\n",
      "Epoch: 658, Iteration: 1/2, Loss: 1.393516321937334\n",
      "Epoch: 659, Iteration: 1/2, Loss: 1.3927548157505818\n",
      "Epoch: 660, Iteration: 1/2, Loss: 1.39327556541279\n",
      "Epoch: 661, Iteration: 1/2, Loss: 1.3927726874986002\n",
      "Epoch: 662, Iteration: 1/2, Loss: 1.3932050507126652\n",
      "Epoch: 663, Iteration: 1/2, Loss: 1.393547815978585\n",
      "Epoch: 664, Iteration: 1/2, Loss: 1.3927002013203102\n",
      "Epoch: 665, Iteration: 1/2, Loss: 1.3935482866583406\n",
      "Epoch: 666, Iteration: 1/2, Loss: 1.393553918082979\n",
      "Epoch: 667, Iteration: 1/2, Loss: 1.3922377865166686\n",
      "Epoch: 668, Iteration: 1/2, Loss: 1.3938308579347551\n",
      "Epoch: 669, Iteration: 1/2, Loss: 1.3926889236672921\n",
      "Epoch: 670, Iteration: 1/2, Loss: 1.3926074673690656\n",
      "Epoch: 671, Iteration: 1/2, Loss: 1.393473036206327\n",
      "Epoch: 672, Iteration: 1/2, Loss: 1.3929566592901916\n",
      "Epoch: 673, Iteration: 1/2, Loss: 1.3930277844207395\n",
      "Epoch: 674, Iteration: 1/2, Loss: 1.393338429819561\n",
      "Epoch: 675, Iteration: 1/2, Loss: 1.3926611604981558\n",
      "Epoch: 676, Iteration: 1/2, Loss: 1.392908480706137\n",
      "Epoch: 677, Iteration: 1/2, Loss: 1.3925324584845993\n",
      "Epoch: 678, Iteration: 1/2, Loss: 1.3932695227397276\n",
      "Epoch: 679, Iteration: 1/2, Loss: 1.392938258672534\n",
      "Epoch: 680, Iteration: 1/2, Loss: 1.39293936527491\n",
      "Epoch: 681, Iteration: 1/2, Loss: 1.392404925564524\n",
      "Epoch: 682, Iteration: 1/2, Loss: 1.3937160490288067\n",
      "Epoch: 683, Iteration: 1/2, Loss: 1.3923508810198273\n",
      "Epoch: 684, Iteration: 1/2, Loss: 1.3928573578372925\n",
      "Epoch: 685, Iteration: 1/2, Loss: 1.3929002547670286\n",
      "Epoch: 686, Iteration: 1/2, Loss: 1.3927274009594193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████▏       | 789/1000 [00:00<00:00, 1064.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 687, Iteration: 1/2, Loss: 1.3927887701391914\n",
      "Epoch: 688, Iteration: 1/2, Loss: 1.3927341270668734\n",
      "Epoch: 689, Iteration: 1/2, Loss: 1.3927923588961193\n",
      "Epoch: 690, Iteration: 1/2, Loss: 1.3931318213586557\n",
      "Epoch: 691, Iteration: 1/2, Loss: 1.392321316310859\n",
      "Epoch: 692, Iteration: 1/2, Loss: 1.3927919052098332\n",
      "Epoch: 693, Iteration: 1/2, Loss: 1.3930304035697065\n",
      "Epoch: 694, Iteration: 1/2, Loss: 1.392241158894584\n",
      "Epoch: 695, Iteration: 1/2, Loss: 1.3923034278632331\n",
      "Epoch: 696, Iteration: 1/2, Loss: 1.3931427585532368\n",
      "Epoch: 697, Iteration: 1/2, Loss: 1.3926231408328364\n",
      "Epoch: 698, Iteration: 1/2, Loss: 1.3927159415641936\n",
      "Epoch: 699, Iteration: 1/2, Loss: 1.3922042297931112\n",
      "Epoch: 700, Iteration: 1/2, Loss: 1.3929053833480651\n",
      "Epoch: 701, Iteration: 1/2, Loss: 1.3925871611698617\n",
      "Epoch: 702, Iteration: 1/2, Loss: 1.3922534773614959\n",
      "Epoch: 703, Iteration: 1/2, Loss: 1.3925762698844986\n",
      "Epoch: 704, Iteration: 1/2, Loss: 1.3932864716813285\n",
      "Epoch: 705, Iteration: 1/2, Loss: 1.3921362672141016\n",
      "Epoch: 706, Iteration: 1/2, Loss: 1.393003334970541\n",
      "Epoch: 707, Iteration: 1/2, Loss: 1.3921514459119388\n",
      "Epoch: 708, Iteration: 1/2, Loss: 1.39210056366974\n",
      "Epoch: 709, Iteration: 1/2, Loss: 1.3928433635741335\n",
      "Epoch: 710, Iteration: 1/2, Loss: 1.3924173203360104\n",
      "Epoch: 711, Iteration: 1/2, Loss: 1.3924160487743338\n",
      "Epoch: 712, Iteration: 1/2, Loss: 1.3925288340897315\n",
      "Epoch: 713, Iteration: 1/2, Loss: 1.3924751110299847\n",
      "Epoch: 714, Iteration: 1/2, Loss: 1.3924098242679641\n",
      "Epoch: 715, Iteration: 1/2, Loss: 1.3924241024442094\n",
      "Epoch: 716, Iteration: 1/2, Loss: 1.3927851744659545\n",
      "Epoch: 717, Iteration: 1/2, Loss: 1.3923147821874624\n",
      "Epoch: 718, Iteration: 1/2, Loss: 1.391986896201397\n",
      "Epoch: 719, Iteration: 1/2, Loss: 1.3923071607208497\n",
      "Epoch: 720, Iteration: 1/2, Loss: 1.3924012364910288\n",
      "Epoch: 721, Iteration: 1/2, Loss: 1.3923224737691928\n",
      "Epoch: 722, Iteration: 1/2, Loss: 1.3920097504440587\n",
      "Epoch: 723, Iteration: 1/2, Loss: 1.393010349231324\n",
      "Epoch: 724, Iteration: 1/2, Loss: 1.3919494213348473\n",
      "Epoch: 725, Iteration: 1/2, Loss: 1.3919386719391893\n",
      "Epoch: 726, Iteration: 1/2, Loss: 1.3925527173054144\n",
      "Epoch: 727, Iteration: 1/2, Loss: 1.3923385523640581\n",
      "Epoch: 728, Iteration: 1/2, Loss: 1.392273777345632\n",
      "Epoch: 729, Iteration: 1/2, Loss: 1.39224482265699\n",
      "Epoch: 730, Iteration: 1/2, Loss: 1.3921167594144073\n",
      "Epoch: 731, Iteration: 1/2, Loss: 1.3923216902277988\n",
      "Epoch: 732, Iteration: 1/2, Loss: 1.3922010682183004\n",
      "Epoch: 733, Iteration: 1/2, Loss: 1.3924983421682824\n",
      "Epoch: 734, Iteration: 1/2, Loss: 1.3914877217249297\n",
      "Epoch: 735, Iteration: 1/2, Loss: 1.3925820576500703\n",
      "Epoch: 736, Iteration: 1/2, Loss: 1.3920864449201658\n",
      "Epoch: 737, Iteration: 1/2, Loss: 1.3920586041772025\n",
      "Epoch: 738, Iteration: 1/2, Loss: 1.392245606246329\n",
      "Epoch: 739, Iteration: 1/2, Loss: 1.3923834000384303\n",
      "Epoch: 740, Iteration: 1/2, Loss: 1.3914747869992317\n",
      "Epoch: 741, Iteration: 1/2, Loss: 1.3923490635250277\n",
      "Epoch: 742, Iteration: 1/2, Loss: 1.3918243313043375\n",
      "Epoch: 743, Iteration: 1/2, Loss: 1.3924815733034919\n",
      "Epoch: 744, Iteration: 1/2, Loss: 1.3919864021299126\n",
      "Epoch: 745, Iteration: 1/2, Loss: 1.3923501377475014\n",
      "Epoch: 746, Iteration: 1/2, Loss: 1.3920381193350129\n",
      "Epoch: 747, Iteration: 1/2, Loss: 1.3916616734559433\n",
      "Epoch: 748, Iteration: 1/2, Loss: 1.3920076828930794\n",
      "Epoch: 749, Iteration: 1/2, Loss: 1.3920045398716772\n",
      "Epoch: 750, Iteration: 1/2, Loss: 1.3920667168510807\n",
      "Epoch: 751, Iteration: 1/2, Loss: 1.3923178734188744\n",
      "Epoch: 752, Iteration: 1/2, Loss: 1.3913081199320627\n",
      "Epoch: 753, Iteration: 1/2, Loss: 1.391960717570132\n",
      "Epoch: 754, Iteration: 1/2, Loss: 1.3922021113145973\n",
      "Epoch: 755, Iteration: 1/2, Loss: 1.3923041714144637\n",
      "Epoch: 756, Iteration: 1/2, Loss: 1.391673269218725\n",
      "Epoch: 757, Iteration: 1/2, Loss: 1.3918033441567108\n",
      "Epoch: 758, Iteration: 1/2, Loss: 1.391946310262611\n",
      "Epoch: 759, Iteration: 1/2, Loss: 1.392255354959666\n",
      "Epoch: 760, Iteration: 1/2, Loss: 1.391633864634228\n",
      "Epoch: 761, Iteration: 1/2, Loss: 1.3917591683903536\n",
      "Epoch: 762, Iteration: 1/2, Loss: 1.3916135951159423\n",
      "Epoch: 763, Iteration: 1/2, Loss: 1.3925228452587624\n",
      "Epoch: 764, Iteration: 1/2, Loss: 1.3913855921485077\n",
      "Epoch: 765, Iteration: 1/2, Loss: 1.3918622477541986\n",
      "Epoch: 766, Iteration: 1/2, Loss: 1.3915724771047508\n",
      "Epoch: 767, Iteration: 1/2, Loss: 1.3920638917282702\n",
      "Epoch: 768, Iteration: 1/2, Loss: 1.3915130915759548\n",
      "Epoch: 769, Iteration: 1/2, Loss: 1.3917886788618714\n",
      "Epoch: 770, Iteration: 1/2, Loss: 1.392469667347667\n",
      "Epoch: 771, Iteration: 1/2, Loss: 1.3916641039249915\n",
      "Epoch: 772, Iteration: 1/2, Loss: 1.3914516809903377\n",
      "Epoch: 773, Iteration: 1/2, Loss: 1.3918391363732532\n",
      "Epoch: 774, Iteration: 1/2, Loss: 1.3916959235353312\n",
      "Epoch: 775, Iteration: 1/2, Loss: 1.3917734179581502\n",
      "Epoch: 776, Iteration: 1/2, Loss: 1.3916755928566267\n",
      "Epoch: 777, Iteration: 1/2, Loss: 1.3913643343069455\n",
      "Epoch: 778, Iteration: 1/2, Loss: 1.3923057101736662\n",
      "Epoch: 779, Iteration: 1/2, Loss: 1.3913453702030614\n",
      "Epoch: 780, Iteration: 1/2, Loss: 1.39139744725441\n",
      "Epoch: 781, Iteration: 1/2, Loss: 1.3920511099465356\n",
      "Epoch: 782, Iteration: 1/2, Loss: 1.3913092699593725\n",
      "Epoch: 783, Iteration: 1/2, Loss: 1.3918818271405735\n",
      "Epoch: 784, Iteration: 1/2, Loss: 1.3920395120637772\n",
      "Epoch: 785, Iteration: 1/2, Loss: 1.3915241790617912\n",
      "Epoch: 786, Iteration: 1/2, Loss: 1.39107692632433\n",
      "Epoch: 787, Iteration: 1/2, Loss: 1.3919094270507182\n",
      "Epoch: 788, Iteration: 1/2, Loss: 1.3915647699250497\n",
      "Epoch: 789, Iteration: 1/2, Loss: 1.3912835712564449\n",
      "Epoch: 790, Iteration: 1/2, Loss: 1.3919087636295093\n",
      "Epoch: 791, Iteration: 1/2, Loss: 1.3915268926779036\n",
      "Epoch: 792, Iteration: 1/2, Loss: 1.3915957557845937\n",
      "Epoch: 793, Iteration: 1/2, Loss: 1.3915761982690866\n",
      "Epoch: 794, Iteration: 1/2, Loss: 1.3911100115881574\n",
      "Epoch: 795, Iteration: 1/2, Loss: 1.391857164773753\n",
      "Epoch: 796, Iteration: 1/2, Loss: 1.3915849501724034\n",
      "Epoch: 797, Iteration: 1/2, Loss: 1.3914411888034364\n",
      "Epoch: 798, Iteration: 1/2, Loss: 1.3915278161877396\n",
      "Epoch: 799, Iteration: 1/2, Loss: 1.391853584650714\n",
      "Epoch: 800, Iteration: 1/2, Loss: 1.3911255091468222\n",
      "Epoch: 801, Iteration: 1/2, Loss: 1.3914031435072016\n",
      "Epoch: 802, Iteration: 1/2, Loss: 1.391814898445666\n",
      "Epoch: 803, Iteration: 1/2, Loss: 1.3914521831842293\n",
      "Epoch: 804, Iteration: 1/2, Loss: 1.391510009019362\n",
      "Epoch: 805, Iteration: 1/2, Loss: 1.3910520972570737\n",
      "Epoch: 806, Iteration: 1/2, Loss: 1.391095579949262\n",
      "Epoch: 807, Iteration: 1/2, Loss: 1.3917954345728831\n",
      "Epoch: 808, Iteration: 1/2, Loss: 1.3913477157310696\n",
      "Epoch: 809, Iteration: 1/2, Loss: 1.391500304006129\n",
      "Epoch: 810, Iteration: 1/2, Loss: 1.3909651767673896\n",
      "Epoch: 811, Iteration: 1/2, Loss: 1.3914374774744405\n",
      "Epoch: 812, Iteration: 1/2, Loss: 1.3913792025914342\n",
      "Epoch: 813, Iteration: 1/2, Loss: 1.3917156639023995\n",
      "Epoch: 814, Iteration: 1/2, Loss: 1.3913131419471672\n",
      "Epoch: 815, Iteration: 1/2, Loss: 1.3915623986004308\n",
      "Epoch: 816, Iteration: 1/2, Loss: 1.3910868278981328\n",
      "Epoch: 817, Iteration: 1/2, Loss: 1.3912865832535564\n",
      "Epoch: 818, Iteration: 1/2, Loss: 1.3914115741782576\n",
      "Epoch: 819, Iteration: 1/2, Loss: 1.390900266722689\n",
      "Epoch: 820, Iteration: 1/2, Loss: 1.391714083573585\n",
      "Epoch: 821, Iteration: 1/2, Loss: 1.3912897338203853\n",
      "Epoch: 822, Iteration: 1/2, Loss: 1.3914592306738087\n",
      "Epoch: 823, Iteration: 1/2, Loss: 1.390738017135371\n",
      "Epoch: 824, Iteration: 1/2, Loss: 1.3915187399741367\n",
      "Epoch: 825, Iteration: 1/2, Loss: 1.3912161930208522\n",
      "Epoch: 826, Iteration: 1/2, Loss: 1.391346973356601\n",
      "Epoch: 827, Iteration: 1/2, Loss: 1.390922141414487\n",
      "Epoch: 828, Iteration: 1/2, Loss: 1.3912384165582763\n",
      "Epoch: 829, Iteration: 1/2, Loss: 1.3915559962000197\n",
      "Epoch: 830, Iteration: 1/2, Loss: 1.3911561568258781\n",
      "Epoch: 831, Iteration: 1/2, Loss: 1.391442492472826\n",
      "Epoch: 832, Iteration: 1/2, Loss: 1.3912244778998595\n",
      "Epoch: 833, Iteration: 1/2, Loss: 1.3912504958387135\n",
      "Epoch: 834, Iteration: 1/2, Loss: 1.390599632919182\n",
      "Epoch: 835, Iteration: 1/2, Loss: 1.3913817054568935\n",
      "Epoch: 836, Iteration: 1/2, Loss: 1.390950386512382\n",
      "Epoch: 837, Iteration: 1/2, Loss: 1.3913897146549776\n",
      "Epoch: 838, Iteration: 1/2, Loss: 1.391153897184409\n",
      "Epoch: 839, Iteration: 1/2, Loss: 1.3911017170858901\n",
      "Epoch: 840, Iteration: 1/2, Loss: 1.3911879965313578\n",
      "Epoch: 841, Iteration: 1/2, Loss: 1.3913571834702005\n",
      "Epoch: 842, Iteration: 1/2, Loss: 1.3908196074008645\n",
      "Epoch: 843, Iteration: 1/2, Loss: 1.3913655317263078\n",
      "Epoch: 844, Iteration: 1/2, Loss: 1.3908627394838367\n",
      "Epoch: 845, Iteration: 1/2, Loss: 1.391058125384728\n",
      "Epoch: 846, Iteration: 1/2, Loss: 1.3911620889837668\n",
      "Epoch: 847, Iteration: 1/2, Loss: 1.3907766617986284\n",
      "Epoch: 848, Iteration: 1/2, Loss: 1.3915339632915957\n",
      "Epoch: 849, Iteration: 1/2, Loss: 1.3907958284921682\n",
      "Epoch: 850, Iteration: 1/2, Loss: 1.3910757642325824\n",
      "Epoch: 851, Iteration: 1/2, Loss: 1.3913057665644515\n",
      "Epoch: 852, Iteration: 1/2, Loss: 1.3906926180442472\n",
      "Epoch: 853, Iteration: 1/2, Loss: 1.3913518796734654\n",
      "Epoch: 854, Iteration: 1/2, Loss: 1.3906955976410336\n",
      "Epoch: 855, Iteration: 1/2, Loss: 1.3907426382288355\n",
      "Epoch: 856, Iteration: 1/2, Loss: 1.3910531665920587\n",
      "Epoch: 857, Iteration: 1/2, Loss: 1.3912317688401852\n",
      "Epoch: 858, Iteration: 1/2, Loss: 1.3909546265992754\n",
      "Epoch: 859, Iteration: 1/2, Loss: 1.3908038052889586\n",
      "Epoch: 860, Iteration: 1/2, Loss: 1.391203020765651\n",
      "Epoch: 861, Iteration: 1/2, Loss: 1.3908984370629192\n",
      "Epoch: 862, Iteration: 1/2, Loss: 1.3909441026761131\n",
      "Epoch: 863, Iteration: 1/2, Loss: 1.391276673699951\n",
      "Epoch: 864, Iteration: 1/2, Loss: 1.3909371964221506\n",
      "Epoch: 865, Iteration: 1/2, Loss: 1.3904090306096721\n",
      "Epoch: 866, Iteration: 1/2, Loss: 1.3911212593989504\n",
      "Epoch: 867, Iteration: 1/2, Loss: 1.390999646078663\n",
      "Epoch: 868, Iteration: 1/2, Loss: 1.3905633172124945\n",
      "Epoch: 869, Iteration: 1/2, Loss: 1.390989255759224\n",
      "Epoch: 870, Iteration: 1/2, Loss: 1.391084764397002\n",
      "Epoch: 871, Iteration: 1/2, Loss: 1.390944809316065\n",
      "Epoch: 872, Iteration: 1/2, Loss: 1.3911097102090204\n",
      "Epoch: 873, Iteration: 1/2, Loss: 1.3906736068310592\n",
      "Epoch: 874, Iteration: 1/2, Loss: 1.3908619844782786\n",
      "Epoch: 875, Iteration: 1/2, Loss: 1.390817207454741\n",
      "Epoch: 876, Iteration: 1/2, Loss: 1.3908752109842775\n",
      "Epoch: 877, Iteration: 1/2, Loss: 1.390718901682232\n",
      "Epoch: 878, Iteration: 1/2, Loss: 1.390587782507311\n",
      "Epoch: 879, Iteration: 1/2, Loss: 1.3908767543702907\n",
      "Epoch: 880, Iteration: 1/2, Loss: 1.3910201156790336\n",
      "Epoch: 881, Iteration: 1/2, Loss: 1.3911741224835978\n",
      "Epoch: 882, Iteration: 1/2, Loss: 1.390752096197645\n",
      "Epoch: 883, Iteration: 1/2, Loss: 1.3903205026049488\n",
      "Epoch: 884, Iteration: 1/2, Loss: 1.3909810406540417\n",
      "Epoch: 885, Iteration: 1/2, Loss: 1.3908036369282113\n",
      "Epoch: 886, Iteration: 1/2, Loss: 1.3909970146136756\n",
      "Epoch: 887, Iteration: 1/2, Loss: 1.3905264762565495\n",
      "Epoch: 888, Iteration: 1/2, Loss: 1.3907512253769783\n",
      "Epoch: 889, Iteration: 1/2, Loss: 1.3904814628282698\n",
      "Epoch: 890, Iteration: 1/2, Loss: 1.3909946462059408\n",
      "Epoch: 891, Iteration: 1/2, Loss: 1.3907670116528847\n",
      "Epoch: 892, Iteration: 1/2, Loss: 1.3906947930078712\n",
      "Epoch: 893, Iteration: 1/2, Loss: 1.3907834755242026\n",
      "Epoch: 894, Iteration: 1/2, Loss: 1.3909370448757472\n",
      "Epoch: 895, Iteration: 1/2, Loss: 1.3905285098305011\n",
      "Epoch: 896, Iteration: 1/2, Loss: 1.3907037033917569\n",
      "Epoch: 897, Iteration: 1/2, Loss: 1.3906106425870688\n",
      "Epoch: 898, Iteration: 1/2, Loss: 1.3907489135017945\n",
      "Epoch: 899, Iteration: 1/2, Loss: 1.390704540442608\n",
      "Epoch: 900, Iteration: 1/2, Loss: 1.390898199401038\n",
      "Epoch: 901, Iteration: 1/2, Loss: 1.3907181428586775\n",
      "Epoch: 902, Iteration: 1/2, Loss: 1.3903701052442359\n",
      "Epoch: 903, Iteration: 1/2, Loss: 1.3903545165851818\n",
      "Epoch: 904, Iteration: 1/2, Loss: 1.390976720129277\n",
      "Epoch: 905, Iteration: 1/2, Loss: 1.3909054310158897\n",
      "Epoch: 906, Iteration: 1/2, Loss: 1.390362988307296\n",
      "Epoch: 907, Iteration: 1/2, Loss: 1.3903598619999515\n",
      "Epoch: 908, Iteration: 1/2, Loss: 1.3905738004376622\n",
      "Epoch: 909, Iteration: 1/2, Loss: 1.390855471640742\n",
      "Epoch: 910, Iteration: 1/2, Loss: 1.3906389684990108\n",
      "Epoch: 911, Iteration: 1/2, Loss: 1.3906861509739952\n",
      "Epoch: 912, Iteration: 1/2, Loss: 1.3907404006697046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1000/1000 [00:00<00:00, 1127.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 913, Iteration: 1/2, Loss: 1.3906246950795649\n",
      "Epoch: 914, Iteration: 1/2, Loss: 1.390370225317966\n",
      "Epoch: 915, Iteration: 1/2, Loss: 1.3908338849837132\n",
      "Epoch: 916, Iteration: 1/2, Loss: 1.3903010769419604\n",
      "Epoch: 917, Iteration: 1/2, Loss: 1.3905441574489308\n",
      "Epoch: 918, Iteration: 1/2, Loss: 1.3907555793624662\n",
      "Epoch: 919, Iteration: 1/2, Loss: 1.3902919603813109\n",
      "Epoch: 920, Iteration: 1/2, Loss: 1.3903072878160676\n",
      "Epoch: 921, Iteration: 1/2, Loss: 1.3907715000629983\n",
      "Epoch: 922, Iteration: 1/2, Loss: 1.3906340539152144\n",
      "Epoch: 923, Iteration: 1/2, Loss: 1.390410059573519\n",
      "Epoch: 924, Iteration: 1/2, Loss: 1.3902918630356815\n",
      "Epoch: 925, Iteration: 1/2, Loss: 1.390566630958871\n",
      "Epoch: 926, Iteration: 1/2, Loss: 1.3907024755816348\n",
      "Epoch: 927, Iteration: 1/2, Loss: 1.3905890343377085\n",
      "Epoch: 928, Iteration: 1/2, Loss: 1.3901936538130042\n",
      "Epoch: 929, Iteration: 1/2, Loss: 1.3907441959696643\n",
      "Epoch: 930, Iteration: 1/2, Loss: 1.3906835746172712\n",
      "Epoch: 931, Iteration: 1/2, Loss: 1.3904449506937402\n",
      "Epoch: 932, Iteration: 1/2, Loss: 1.3904930005806984\n",
      "Epoch: 933, Iteration: 1/2, Loss: 1.3902574279797475\n",
      "Epoch: 934, Iteration: 1/2, Loss: 1.3906547800415021\n",
      "Epoch: 935, Iteration: 1/2, Loss: 1.3902813464196213\n",
      "Epoch: 936, Iteration: 1/2, Loss: 1.390606253570284\n",
      "Epoch: 937, Iteration: 1/2, Loss: 1.3904346411949144\n",
      "Epoch: 938, Iteration: 1/2, Loss: 1.3904831849782828\n",
      "Epoch: 939, Iteration: 1/2, Loss: 1.3903673029527088\n",
      "Epoch: 940, Iteration: 1/2, Loss: 1.389913940572142\n",
      "Epoch: 941, Iteration: 1/2, Loss: 1.3904106382377555\n",
      "Epoch: 942, Iteration: 1/2, Loss: 1.3904045089572166\n",
      "Epoch: 943, Iteration: 1/2, Loss: 1.3906159336021076\n",
      "Epoch: 944, Iteration: 1/2, Loss: 1.3904462707719332\n",
      "Epoch: 945, Iteration: 1/2, Loss: 1.3903601962164438\n",
      "Epoch: 946, Iteration: 1/2, Loss: 1.3904692147990496\n",
      "Epoch: 947, Iteration: 1/2, Loss: 1.3903364787351609\n",
      "Epoch: 948, Iteration: 1/2, Loss: 1.390322143625136\n",
      "Epoch: 949, Iteration: 1/2, Loss: 1.390406800580992\n",
      "Epoch: 950, Iteration: 1/2, Loss: 1.390328826193711\n",
      "Epoch: 951, Iteration: 1/2, Loss: 1.3903595840105565\n",
      "Epoch: 952, Iteration: 1/2, Loss: 1.390558090457048\n",
      "Epoch: 953, Iteration: 1/2, Loss: 1.390177520174639\n",
      "Epoch: 954, Iteration: 1/2, Loss: 1.3903233192076252\n",
      "Epoch: 955, Iteration: 1/2, Loss: 1.3902458652741863\n",
      "Epoch: 956, Iteration: 1/2, Loss: 1.390576689890085\n",
      "Epoch: 957, Iteration: 1/2, Loss: 1.3900579127254384\n",
      "Epoch: 958, Iteration: 1/2, Loss: 1.390360003793056\n",
      "Epoch: 959, Iteration: 1/2, Loss: 1.390330524937483\n",
      "Epoch: 960, Iteration: 1/2, Loss: 1.3904721615930884\n",
      "Epoch: 961, Iteration: 1/2, Loss: 1.389841665125966\n",
      "Epoch: 962, Iteration: 1/2, Loss: 1.3907340479484924\n",
      "Epoch: 963, Iteration: 1/2, Loss: 1.3898401937819558\n",
      "Epoch: 964, Iteration: 1/2, Loss: 1.3905118422284823\n",
      "Epoch: 965, Iteration: 1/2, Loss: 1.3903026507448915\n",
      "Epoch: 966, Iteration: 1/2, Loss: 1.3902271667961317\n",
      "Epoch: 967, Iteration: 1/2, Loss: 1.3902122069754443\n",
      "Epoch: 968, Iteration: 1/2, Loss: 1.3902144174052407\n",
      "Epoch: 969, Iteration: 1/2, Loss: 1.3903077173808673\n",
      "Epoch: 970, Iteration: 1/2, Loss: 1.3902294076764155\n",
      "Epoch: 971, Iteration: 1/2, Loss: 1.3900178746656435\n",
      "Epoch: 972, Iteration: 1/2, Loss: 1.390228645354235\n",
      "Epoch: 973, Iteration: 1/2, Loss: 1.3904482331092085\n",
      "Epoch: 974, Iteration: 1/2, Loss: 1.3903971027549646\n",
      "Epoch: 975, Iteration: 1/2, Loss: 1.3900561392654154\n",
      "Epoch: 976, Iteration: 1/2, Loss: 1.390180966006223\n",
      "Epoch: 977, Iteration: 1/2, Loss: 1.3904141403495407\n",
      "Epoch: 978, Iteration: 1/2, Loss: 1.3899462124682493\n",
      "Epoch: 979, Iteration: 1/2, Loss: 1.3904022794858242\n",
      "Epoch: 980, Iteration: 1/2, Loss: 1.3900482881417038\n",
      "Epoch: 981, Iteration: 1/2, Loss: 1.3903130550456348\n",
      "Epoch: 982, Iteration: 1/2, Loss: 1.3902500372338555\n",
      "Epoch: 983, Iteration: 1/2, Loss: 1.3899549468337924\n",
      "Epoch: 984, Iteration: 1/2, Loss: 1.3902957987633187\n",
      "Epoch: 985, Iteration: 1/2, Loss: 1.389953578777546\n",
      "Epoch: 986, Iteration: 1/2, Loss: 1.3904300705041808\n",
      "Epoch: 987, Iteration: 1/2, Loss: 1.3899163138650301\n",
      "Epoch: 988, Iteration: 1/2, Loss: 1.3900887631764527\n",
      "Epoch: 989, Iteration: 1/2, Loss: 1.3901352511248632\n",
      "Epoch: 990, Iteration: 1/2, Loss: 1.3903644353700395\n",
      "Epoch: 991, Iteration: 1/2, Loss: 1.389880154270336\n",
      "Epoch: 992, Iteration: 1/2, Loss: 1.3903530394485006\n",
      "Epoch: 993, Iteration: 1/2, Loss: 1.3899553294769627\n",
      "Epoch: 994, Iteration: 1/2, Loss: 1.3900657328253971\n",
      "Epoch: 995, Iteration: 1/2, Loss: 1.3900760313195244\n",
      "Epoch: 996, Iteration: 1/2, Loss: 1.390089307523748\n",
      "Epoch: 997, Iteration: 1/2, Loss: 1.3900740187414713\n",
      "Epoch: 998, Iteration: 1/2, Loss: 1.390078335947513\n",
      "Epoch: 999, Iteration: 1/2, Loss: 1.3901581679323063\n",
      "Epoch: 1000, Iteration: 1/2, Loss: 1.3900497183314116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "\n",
    "# configurations\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "# define model\n",
    "skip_gram = SkipGram(vocab_size=len(word2idx), hidden_size=hidden_size, window_size=window_size) ### <your code> ###\n",
    "sgd_optimizer = SGD()\n",
    "trainer = Trainer(skip_gram, sgd_optimizer)\n",
    "\n",
    "# start training\n",
    "trainer.fit(contexts, targets, max_epoch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 am [ 0.53572756 -2.2233667  -1.1826382  -0.6290156  -1.0183727 ]\n",
      "1 i [ 0.01425028 -0.01052956 -0.00406308  0.00380864  0.00675842]\n",
      "2 studying [-0.7869051   1.3618098  -0.16281328  0.40391758 -2.3052213 ]\n",
      "3 . [ 0.00179054 -0.01607007  0.00771282  0.01456084  0.01127212]\n",
      "4 processing [-1.2712989  0.5871648  1.592158  -1.1276559  1.4846514]\n",
      "5 language [ 1.152474   1.6932524 -0.4447889  2.291982  -0.6203123]\n",
      "6 natural [-0.7921553  -0.9477937  -0.08786593 -2.8920374   0.02463147]\n",
      "7 now [ 1.2955494  -0.20403956 -0.10508148  1.6701022   1.9023067 ]\n"
     ]
    }
   ],
   "source": [
    "# check skip-gram results\n",
    "### <your code> ###\n",
    "word_vecs = skip_gram.word_vecs\n",
    "for word_id, word in idx2word.items():\n",
    "    print(word_id, word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
