{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day23_Attention mechanism_homework.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LS5-4HlCiz_y","executionInfo":{"status":"ok","timestamp":1618205204840,"user_tz":-480,"elapsed":37146,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"c4e3360d-0988-40dc-cac5-ca6cefc0f897"},"source":["# Mount Google Drive to Colab\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jGjYOVlYi3dl","executionInfo":{"status":"ok","timestamp":1618205205303,"user_tz":-480,"elapsed":11531,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"0ff51e4b-00e4-4f6a-e713-d1c002508fc2"},"source":["!pwd\n","#!ls -al\n","%cd '/content/gdrive/My Drive/NLP/Part2'\n","#!ls -al"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content\n","/content/gdrive/My Drive/NLP/Part2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gCIvz30AOj-H"},"source":["# 作業 : 觀察機器翻譯 ATTENTION 內容 \n","- 仔細地觀察機器翻譯 ATTENTION 結果"]},{"cell_type":"markdown","metadata":{"id":"usP1_X7qOv6F"},"source":["# [作業目標]\n","- 透過視覺化 注意力 attention 層 了解attention 的作用方式"]},{"cell_type":"markdown","metadata":{"id":"fWGLeN9BOxEF"},"source":["# [作業重點]\n","- 透過視覺化 注意力 attention 層 了解attention 的作用方式\n","- 原則上只要之前的訓練有跑完，這邊的程式可以執行成功最後只要觀察結果就好\n"]},{"cell_type":"code","metadata":{"id":"UIBD2Nn-OI-1","executionInfo":{"status":"ok","timestamp":1618205224431,"user_tz":-480,"elapsed":5389,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","#from torchtext.data import Field, BucketIterator, TabularDataset\n","from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n","from sklearn.model_selection import train_test_split\n","import csv\n","\n","import numpy as np\n","import re\n","import random\n","import math\n","import time\n","\n","import csv\n","import spacy"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzDaUBdcjXQ5","executionInfo":{"status":"ok","timestamp":1618205319237,"user_tz":-480,"elapsed":9102,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"8d4c39c8-50fc-45f1-fd80-3f6acaec7151"},"source":["!mkdir ./data\n","!mkdir ./data/multi30k\n","!python -m spacy download en\n","!ls ./data/multi30k -al\n","spacy_english = spacy.load(\"en_core_web_sm\")\n","!ls ./data/multi30k -al"],"execution_count":7,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘./data’: File exists\n","mkdir: cannot create directory ‘./data/multi30k’: File exists\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","total 5448\n","-rw------- 1 root root   66154 Apr  7 09:05 mmt_task1_test2016.tar.gz\n","-rw------- 1 root root   70649 Oct 17  2016 test2016.de\n","-rw------- 1 root root   62076 Oct 17  2016 test2016.en\n","-rw------- 1 root root   72261 Feb 11  2017 test2016.fr\n","-rw------- 1 root root 2110399 Feb  2  2016 train.de\n","-rw------- 1 root root 1801239 Feb  2  2016 train.en\n","-rw------- 1 root root 1207136 Apr  7 09:05 training.tar.gz\n","-rw------- 1 root root   75920 Feb  2  2016 val.de\n","-rw------- 1 root root   63298 Feb  2  2016 val.en\n","-rw------- 1 root root   46329 Apr  7 09:05 validation.tar.gz\n","total 5448\n","-rw------- 1 root root   66154 Apr  7 09:05 mmt_task1_test2016.tar.gz\n","-rw------- 1 root root   70649 Oct 17  2016 test2016.de\n","-rw------- 1 root root   62076 Oct 17  2016 test2016.en\n","-rw------- 1 root root   72261 Feb 11  2017 test2016.fr\n","-rw------- 1 root root 2110399 Feb  2  2016 train.de\n","-rw------- 1 root root 1801239 Feb  2  2016 train.en\n","-rw------- 1 root root 1207136 Apr  7 09:05 training.tar.gz\n","-rw------- 1 root root   75920 Feb  2  2016 val.de\n","-rw------- 1 root root   63298 Feb  2  2016 val.en\n","-rw------- 1 root root   46329 Apr  7 09:05 validation.tar.gz\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLQlw-62jQ1Z","executionInfo":{"status":"ok","timestamp":1618205322323,"user_tz":-480,"elapsed":901,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"7ac85ba4-ddbb-4a91-885e-8ba3c5cf3af1"},"source":["ls -al /usr/local/lib/python3.7/dist-packages/matplotlib/mpl-data/fonts/ttf"],"execution_count":8,"outputs":[{"output_type":"stream","text":["total 6836\n","drwxr-sr-x 2 root staff   4096 Apr  7 13:48 \u001b[0m\u001b[01;34m.\u001b[0m/\n","drwxr-sr-x 5 root staff   4096 Apr  7 13:48 \u001b[01;34m..\u001b[0m/\n","-rw-r--r-- 1 root staff  25680 Apr  7 13:40 cmb10.ttf\n","-rw-r--r-- 1 root staff  21092 Apr  7 13:40 cmex10.ttf\n","-rw-r--r-- 1 root staff  32560 Apr  7 13:40 cmmi10.ttf\n","-rw-r--r-- 1 root staff  26348 Apr  7 13:40 cmr10.ttf\n","-rw-r--r-- 1 root staff  20376 Apr  7 13:40 cmss10.ttf\n","-rw-r--r-- 1 root staff  29396 Apr  7 13:40 cmsy10.ttf\n","-rw-r--r-- 1 root staff  28136 Apr  7 13:40 cmtt10.ttf\n","-rw-r--r-- 1 root staff 641720 Apr  7 13:40 DejaVuSans-BoldOblique.ttf\n","-rw-r--r-- 1 root staff 704128 Apr  7 13:40 DejaVuSans-Bold.ttf\n","-rw-r--r-- 1 root staff  25712 Apr  7 13:40 DejaVuSansDisplay.ttf\n","-rw-r--r-- 1 root staff 253116 Apr  7 13:40 DejaVuSansMono-BoldOblique.ttf\n","-rw-r--r-- 1 root staff 331536 Apr  7 13:40 DejaVuSansMono-Bold.ttf\n","-rw-r--r-- 1 root staff 251472 Apr  7 13:40 DejaVuSansMono-Oblique.ttf\n","-rw-r--r-- 1 root staff 340240 Apr  7 13:40 DejaVuSansMono.ttf\n","-rw-r--r-- 1 root staff 633840 Apr  7 13:40 DejaVuSans-Oblique.ttf\n","-rw-r--r-- 1 root staff 756072 Apr  7 13:40 DejaVuSans.ttf\n","-rw-r--r-- 1 root staff 347064 Apr  7 13:40 DejaVuSerif-BoldItalic.ttf\n","-rw-r--r-- 1 root staff 355692 Apr  7 13:40 DejaVuSerif-Bold.ttf\n","-rw-r--r-- 1 root staff  14300 Apr  7 13:40 DejaVuSerifDisplay.ttf\n","-rw-r--r-- 1 root staff 345612 Apr  7 13:40 DejaVuSerif-Italic.ttf\n","-rw-r--r-- 1 root staff 379740 Apr  7 13:40 DejaVuSerif.ttf\n","-rw-r--r-- 1 root staff   4816 Apr  7 13:40 LICENSE_DEJAVU\n","-rw-r--r-- 1 root staff   5475 Apr  7 13:40 LICENSE_STIX\n","-rw-r--r-- 1 root staff 181152 Apr  7 13:40 STIXGeneralBolIta.ttf\n","-rw-r--r-- 1 root staff 237360 Apr  7 13:40 STIXGeneralBol.ttf\n","-rw-r--r-- 1 root staff 175040 Apr  7 13:40 STIXGeneralItalic.ttf\n","-rw-r--r-- 1 root staff 448228 Apr  7 13:40 STIXGeneral.ttf\n","-rw-r--r-- 1 root staff  41272 Apr  7 13:40 STIXNonUniBolIta.ttf\n","-rw-r--r-- 1 root staff  30512 Apr  7 13:40 STIXNonUniBol.ttf\n","-rw-r--r-- 1 root staff  46752 Apr  7 13:40 STIXNonUniIta.ttf\n","-rw-r--r-- 1 root staff  59108 Apr  7 13:40 STIXNonUni.ttf\n","-rw-r--r-- 1 root staff  13656 Apr  7 13:40 STIXSizFiveSymReg.ttf\n","-rw-r--r-- 1 root staff  12228 Apr  7 13:40 STIXSizFourSymBol.ttf\n","-rw-r--r-- 1 root staff  15972 Apr  7 13:40 STIXSizFourSymReg.ttf\n","-rw-r--r-- 1 root staff  12556 Apr  7 13:40 STIXSizOneSymBol.ttf\n","-rw-r--r-- 1 root staff  19760 Apr  7 13:40 STIXSizOneSymReg.ttf\n","-rw-r--r-- 1 root staff  12192 Apr  7 13:40 STIXSizThreeSymBol.ttf\n","-rw-r--r-- 1 root staff  15836 Apr  7 13:40 STIXSizThreeSymReg.ttf\n","-rw-r--r-- 1 root staff  12116 Apr  7 13:40 STIXSizTwoSymBol.ttf\n","-rw-r--r-- 1 root staff  15704 Apr  7 13:40 STIXSizTwoSymReg.ttf\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQoAR8K-RyHd","executionInfo":{"status":"ok","timestamp":1618205359826,"user_tz":-480,"elapsed":3303,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"10ed6496-2a75-4de2-91f6-45c10f412dd8"},"source":["9# Colab 進行matplotlib繪圖時顯示繁體中文\n","# 下載字體並命名taipei_sans_tc_beta.ttf，移至指定路徑\n","!wget -O taipei_sans_tc_beta.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n","!mv taipei_sans_tc_beta.ttf /usr/local/lib/python3.7/dist-packages/matplotlib//mpl-data/fonts/ttf\n","\n","from matplotlib.font_manager import FontProperties\n","import matplotlib.pyplot as plt \n","plt.style.use(\"seaborn-whitegrid\")\n","import matplotlib.ticker as ticker\n","# 自定義字體變數\n","myfont = FontProperties(fname=r'/usr/local/lib/python3.7/dist-packages/matplotlib/mpl-data/fonts/ttf/taipei_sans_tc_beta.ttf')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["--2021-04-12 05:29:16--  https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n","Resolving drive.google.com (drive.google.com)... 64.233.189.138, 64.233.189.100, 64.233.189.113, ...\n","Connecting to drive.google.com (drive.google.com)|64.233.189.138|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ptu6vs7vs58oct21eh36temllurqlr9j/1618205325000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_ [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-04-12 05:29:18--  https://doc-0k-9o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ptu6vs7vs58oct21eh36temllurqlr9j/1618205325000/02847987870453524430/*/1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_\n","Resolving doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)... 108.177.97.132, 2404:6800:4008:c00::84\n","Connecting to doc-0k-9o-docs.googleusercontent.com (doc-0k-9o-docs.googleusercontent.com)|108.177.97.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/x-font-ttf]\n","Saving to: ‘taipei_sans_tc_beta.ttf’\n","\n","taipei_sans_tc_beta     [   <=>              ]  19.70M  44.5MB/s    in 0.4s    \n","\n","2021-04-12 05:29:19 (44.5 MB/s) - ‘taipei_sans_tc_beta.ttf’ saved [20659344]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFjVGqegR5U8","executionInfo":{"status":"ok","timestamp":1618206129695,"user_tz":-480,"elapsed":866,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"b9449887-1717-41c6-fa2d-a6cd60c4224d"},"source":["data_dir = '/content/drive/My Drive/NLP/Part2/data/'\n","lines = open(data_dir + 'cmn.txt' , encoding='utf-8').read().strip().split('\\n')\n","trnslt_pairs = [[s for s in l.split('\\t')] for l in lines ]\n","print (\"Sample: \" , trnslt_pairs[1000][0:2] )\n","print (\"Total records:\" , len(trnslt_pairs))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Sample:  ['He was drowned.', '他被淹死了。']\n","Total records: 24360\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tl-KIM-nSA-H","executionInfo":{"status":"ok","timestamp":1618206189037,"user_tz":-480,"elapsed":2727,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"182c692d-98b4-492e-f5e6-8fe847772116"},"source":["# 下載 spacy 的英文模型 幫我們做tokenize\n","model_dir =  '/content/drive/My Drive/NLP/Part2/model/'\n","\n","spacy_eng = spacy.load('en_core_web_sm')\n","def tokenize_eng(text):\n","  #清除不需要的字符\n","  text = re.sub(r\"([.!?])\", r\" \\1\", text)\n","  return [tok.text for tok in spacy_eng.tokenizer(text)]\n","\n","TRG = Field(tokenize = tokenize_eng, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","\n","\n","def tokenize_cmn(text):\n","  #去掉非中文字元\n","  regex = re.compile(r'[^\\u4e00-\\u9fa5A-Za-z0-9]')\n","  text = regex.sub(' ', text)\n","\n","  return [word for word in text if word.strip()]\n","    \n","\n","SRC = Field(tokenize = tokenize_cmn, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True, \n","            include_lengths = True)\n","\n","\n","\n","\n","train_dataset, dev_dataset, test_dataset = TabularDataset.splits(\n","    path = data_dir , format = 'csv', skip_header = True,\n","    train='train.csv', validation='val.csv', test='test.csv',\n","    fields=[\n","        ('trg', TRG),\n","        ('src', SRC)\n","    ]\n",")\n","\n","\n","# 讀取之前儲存的 vocabulary\n","SRC.vocab = torch.load(model_dir + 'SRC_vocab.pt')\n","TRG.vocab = torch.load(model_dir + 'TRG_vocab.pt')\n","\n","print (\"中文語料的字元表長度: \" , len(SRC.vocab) , \", 英文的字元表長度: \" ,len(TRG.vocab))\n","print (\"Sample SRC:\", test_dataset[0].src , \"TRG:\", test_dataset[0].trg)\n","\n","BATCH_SIZE = 128\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_dataset, dev_dataset, test_dataset), \n","     batch_size = BATCH_SIZE,\n","     sort_within_batch = True,\n","     sort_key = lambda x : len(x.src),\n","     device = device)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["中文語料的字元表長度:  2696 , 英文的字元表長度:  4105\n","Sample SRC: ['你', '选', '好', '专', '业', '了', '吗'] TRG: ['have', 'you', 'chosen', 'a', 'major', 'yet', '?']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lYoqlKcrq2Z_"},"source":["# 模型主體 和前面範例程式一樣\n","\n"]},{"cell_type":"code","metadata":{"id":"wj3ZTHDMSGOF","executionInfo":{"status":"ok","timestamp":1618205557554,"user_tz":-480,"elapsed":991,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":["class Attention(nn.Module):\n","  def __init__(self, enc_hid_dim, dec_hid_dim):\n","    super().__init__()\n","\n","  def forward(self, hidden, encoder_outputs, mask):\n","    # hidden bz , dec_hid_dim\n","    # encoder_outputs src len, bz , enc_hid_dim x 2\n","    # mask bz , src len\n","    \n","    batch_size = encoder_outputs.shape[1]\n","    src_len = encoder_outputs.shape[0]\n","\n","    hidden = hidden.unsqueeze(1) \n","    # hidden unsqueeze bz , 1 , dec_hid_dim\n","\n","    attention = torch.matmul( hidden , encoder_outputs.permute(1, 2, 0)   )\n","    # attention bz, 1 , src len\n","    \n","    attention = attention.squeeze(1)\n","    # squeeze bz , src len\n","\n","    attention = attention.masked_fill(mask == 0, -1e10)\n","\n","    return F.softmax(attention, dim = 1)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNzgZqHcS2CX","executionInfo":{"status":"ok","timestamp":1618206217295,"user_tz":-480,"elapsed":1058,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":["class RNNEncoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        # 雙向 ＧＲＵ encoder \n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","        \n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_len):\n","        \n","        #src shape [src len, batch size]\n","        #src_len shape [batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        \n","        #embedded shape [src len, batch size, emb dim]\n","                \n","        # 使用pack_padded_sequence 來壓縮序列        \n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len)\n","                \n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","\n","        # 使用 pad_packed_sequence 用來展開序列成原本形狀的      \n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n","            \n","            \n","        #outputs shape [src len, batch size, hid dim * num directions]\n","        #hidden shape [n layers * num directions, batch size, hid dim]\n","        \n","        #hidden 堆疊 [forward_1, backward_1, forward_2, backward_2, ...]\n","        #outputs 是最後一層 \n","        \n","        #hidden [-2, :, : ] 是最後一層 forwards RNN \n","        #hidden [-1, :, : ] 是最後一層 backwards RNN\n","        \n","        # hidden 是最後再過一層 dense layer\n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        \n","        #outputs shape [src len, batch size, enc hid dim * 2]\n","        #hidden shape [batch size, dec hid dim]\n","        \n","        return outputs, hidden\n","\n","class RNNDecoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        # 單向 ＧＲＵ decoder \n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","        \n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs, mask):\n","             \n","        #input shape [batch size]\n","        #hidden shape [batch size, dec hid dim]\n","        #encoder_outputs shape [src len, batch size, enc hid dim * 2]\n","        #mask shape [batch size, src len]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        #input shape [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        \n","        #embedded shape [1, batch size, emb dim]\n","        \n","        a = self.attention(hidden, encoder_outputs, mask)\n","                \n","        #a shape [batch size, src len]\n","        \n","        a = a.unsqueeze(1)\n","        \n","        #a shape [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #encoder_outputs shape [batch size, src len, enc hid dim * 2]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        \n","        #weighted shape [batch size, 1, enc hid dim * 2]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        \n","        #weighted shape [1, batch size, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        \n","        #rnn_input shape [1, batch size, (enc hid dim * 2) + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        \n","        #output shape [seq len, batch size, dec hid dim * n directions]\n","        #hidden shape [n layers * n directions, batch size, dec hid dim]\n","        \n","        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        #output shape [1, batch size, dec hid dim]\n","        #hidden shape [1, batch size, dec hid dim]\n","        #this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        \n","        #prediction shape [batch size, output dim]\n","        \n","        return prediction, hidden.squeeze(0), a.squeeze(1)\n","\n","class Seq2SeqATTN(nn.Module):\n","    def __init__(self, encoder, decoder, src_pad_idx, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.device = device\n","        \n","    def create_mask(self, src):\n","        mask = (src != self.src_pad_idx).permute(1, 0)\n","        return mask\n","        \n","    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n","        \n","        #src = [src len, batch size]\n","        #src_len = [batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n","                    \n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence, back and forwards\n","        #hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src, src_len)\n","                \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        mask = self.create_mask(src)\n","\n","        #mask = [batch size, src len]\n","                \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden state, all encoder hidden states \n","            #  and mask\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","            \n","        return outputs"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlITuy6WS47j","executionInfo":{"status":"ok","timestamp":1618205453605,"user_tz":-480,"elapsed":767,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"50mOv4N-S8LJ","executionInfo":{"status":"ok","timestamp":1618205454955,"user_tz":-480,"elapsed":1205,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pW2KIxhxrMGf"},"source":["# 建立模型和重要參數 請保持和前面訓練時一樣"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybIY0kKGS_gI","executionInfo":{"status":"ok","timestamp":1618206228911,"user_tz":-480,"elapsed":1059,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"d8e449b3-eeb6-42d9-b4ff-edc822353d60"},"source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 256 # 注意 encoder hidden layer 設定 必須為 dec 的一半 \n","DEC_HID_DIM = 512\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","\n","LEARNING_RATE = 0.002\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = RNNEncoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = RNNDecoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","model = Seq2SeqATTN(enc, dec, SRC_PAD_IDX, device).to(device)\n","\n","optimizer = optim.Adam(model.parameters(),lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n","\n","\n","def initial_mdl_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(initial_mdl_weights)\n","print (\"模型全部參數量: {:10,d} \".format(sum(p.numel() for p in model.parameters())))\n","model"],"execution_count":42,"outputs":[{"output_type":"stream","text":["模型全部參數量: 10,020,873 \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["Seq2SeqATTN(\n","  (encoder): RNNEncoder(\n","    (embedding): Embedding(2696, 256)\n","    (rnn): GRU(256, 256, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): RNNDecoder(\n","    (attention): Attention()\n","    (embedding): Embedding(4105, 256)\n","    (rnn): GRU(768, 512)\n","    (fc_out): Linear(in_features=1280, out_features=4105, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"KOpjxQJmTDYU","executionInfo":{"status":"ok","timestamp":1618206310576,"user_tz":-480,"elapsed":913,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src, src_len = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, src_len.cpu(), trg, 0) #turn off teacher forcing\n","            \n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ukg9t_iOTHlG","executionInfo":{"status":"ok","timestamp":1618206315467,"user_tz":-480,"elapsed":1176,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"76afb8bf-7dfb-459b-dcfd-a7c5eda26625"},"source":["model_dir =  '/content/drive/My Drive/NLP/Part2/model/'\n","model.load_state_dict(torch.load(model_dir + 'best-model.pt'))\n","#model.load_state_dict(torch.load(model_dir + 'model-7.pt'))\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"],"execution_count":46,"outputs":[{"output_type":"stream","text":["| Test Loss: 3.662 | Test PPL:  38.943 |\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-caE1Y1TL5p","executionInfo":{"status":"ok","timestamp":1618206329772,"user_tz":-480,"elapsed":3140,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":["def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n","\n","    model.eval()\n","        \n","    #if isinstance(sentence, str):\n","    #    nlp = spacy_en = spacy.load('en_core_web_sm')\n","    #    tokens = [token.text.lower() for token in spacy_en(sentence)]\n","    #else:\n","    #    tokens = [token.lower() for token in sentence]\n","\n","    tokens = [token.lower() for token in sentence]\n","        \n","    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n","        \n","    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n","    \n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","\n","    src_len = torch.LongTensor([len(src_indexes)]).to(device)\n","    \n","    with torch.no_grad():\n","        encoder_outputs, hidden = model.encoder(src_tensor, src_len.cpu())\n","\n","    mask = model.create_mask(src_tensor)\n","        \n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","\n","    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\n","    \n","    for i in range(max_len):\n","\n","        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n","                \n","        with torch.no_grad():\n","            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\n","\n","        attentions[i] = attention\n","            \n","        pred_token = output.argmax(1).item()\n","        \n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","    \n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","    \n","    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jhh_5_SYYLT","executionInfo":{"status":"ok","timestamp":1618206332142,"user_tz":-480,"elapsed":2496,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}}},"source":["def display_attention(sentence, translation, attention):\n","    \n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    \n","    attention = attention.squeeze(1).cpu().detach().numpy()\n","    \n","    cax = ax.matshow(attention, cmap='bone')\n","   \n","    #fontdict = {\"fontproperties\": zhfont}\n","    \n","    #ax.set_xticks(range(max(max_len_tar, len(predicted_seq))))\n","    #ax.set_xlim(-0.5, max_len_tar -1.5)\n","    \n","    #ax.set_yticks(range(len(sentence) + 2))\n","    #ax.set_xticklabels([subword_encoder_zh.decode([i]) for i in predicted_seq \n","    #                    if i < subword_encoder_zh.vocab_size], \n","    #                   fontdict=fontdict, fontsize=18)\n","    \n","    #plt.rcParams[\"font.family\"]=\"sans-serif\"\n","    #plt.rcParams['font.sans-serif']=['STSong'] #用来正常显示中文标签\n","    \n","    ax.tick_params(labelsize=15)\n","    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n","                       rotation=45 , fontproperties=myfont) #, fontdict=fontdict)\n","    ax.set_yticklabels(['']+translation, fontproperties=myfont) # , fontdict=fontdict)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","    plt.close()"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V4n7915Mrcs1"},"source":["# 作業重點\n","## 請選擇一個好的翻譯結果\n","## 將其 ATTENTION 視覺化 \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRYXjqgvYb-E","executionInfo":{"status":"ok","timestamp":1618206507924,"user_tz":-480,"elapsed":858,"user":{"displayName":"Tu Angus","photoUrl":"","userId":"13639675632472162428"}},"outputId":"b71fb881-518a-472a-e19a-82c15d280879"},"source":["# 請在這邊自行調整 sample index \n","# 觀察不同句子的 ATTENTION 結果\n","example_idx = 899\n","\n","src = vars(train_dataset.examples[example_idx])['src']\n","trg = vars(train_dataset.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')\n","\n","translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')"],"execution_count":63,"outputs":[{"output_type":"stream","text":["src = ['你', '能', '檢', '查', '一', '下', '這', '個', '輪', '胎', '的', '氣', '壓', '嗎']\n","trg = ['could', 'you', 'check', 'the', 'tire', 'pressure', '?']\n","predicted trg = ['could', 'you', 'check', 'this', 'tire', 'tire', '?', '<eos>']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2cdlptGJrsfv"},"source":["# 請觀察翻譯文 和被翻譯文的語意對應"]},{"cell_type":"code","metadata":{"id":"H8f8csPSYfkU"},"source":["print (\"\".join(src ))\n","display_attention(src, translation, attention)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ake_IJd2YiG3"},"source":[""],"execution_count":null,"outputs":[]}]}