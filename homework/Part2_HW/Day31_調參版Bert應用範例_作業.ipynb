{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Day31_調參版Bert應用範例_作業.ipynb","provenance":[],"collapsed_sections":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"2338bdd74de9408b8d4fcff802c59846":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_727dfee5bf384639990b339d903a3492","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bd3bea70950c4797b7bcaafe302bb82a","IPY_MODEL_1ae090c199a246548f42b057fd82f049"]}},"727dfee5bf384639990b339d903a3492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd3bea70950c4797b7bcaafe302bb82a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7e2366b026104e09b31ec0b83db7b32e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b337b16fb42947eea0740bd8180fbd71"}},"1ae090c199a246548f42b057fd82f049":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_de977816d5a74fd2bb02592d1ae9362f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:01&lt;00:00, 163kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e719d3282f474fc5bb71d35e6b859d4a"}},"7e2366b026104e09b31ec0b83db7b32e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b337b16fb42947eea0740bd8180fbd71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de977816d5a74fd2bb02592d1ae9362f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e719d3282f474fc5bb71d35e6b859d4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17bed22e44304a75b52b4d220d10bc25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_338e1f7900b4423ba4ef7189796f7978","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_58cfc3f4d8cc4371ac645511d59ba80b","IPY_MODEL_b2d181c022ec41cfb7efbe80b4a8c116"]}},"338e1f7900b4423ba4ef7189796f7978":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58cfc3f4d8cc4371ac645511d59ba80b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_680c75b3fd114c1fb028ed40a99bed2d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":28,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1dbe43db01314559a86ab6b941f6fd07"}},"b2d181c022ec41cfb7efbe80b4a8c116":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a61ce1b8a814f7ca868f5e0d8ac38ab","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 28.0/28.0 [00:01&lt;00:00, 16.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7d8fdada0934c5eb1ba0e0e80a40f45"}},"680c75b3fd114c1fb028ed40a99bed2d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1dbe43db01314559a86ab6b941f6fd07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a61ce1b8a814f7ca868f5e0d8ac38ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e7d8fdada0934c5eb1ba0e0e80a40f45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0e1245567804a599c8153556c0a04d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_426688c62817440dabcfa1088b7ac138","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4894272bbbd74848ad359ffb41b73fa2","IPY_MODEL_782792d7553b4a2ea99b937db1802835"]}},"426688c62817440dabcfa1088b7ac138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4894272bbbd74848ad359ffb41b73fa2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e635c4cb99724085885dbe8f5142dfc7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":466062,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":466062,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a09a5595ceec4fb3bbe8bc88d110f91d"}},"782792d7553b4a2ea99b937db1802835":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8244c443e0734f2f9491d284620544a1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 466k/466k [00:00&lt;00:00, 2.17MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d032c13b21e4d0dba8bd631804ee941"}},"e635c4cb99724085885dbe8f5142dfc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a09a5595ceec4fb3bbe8bc88d110f91d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8244c443e0734f2f9491d284620544a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d032c13b21e4d0dba8bd631804ee941":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a27a328d2c4243a5a6e4612528f4bf89":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_07746d573ef74d378bedc425a9828053","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6e249eaf7a1d42a895520240b21f1fa1","IPY_MODEL_5cd094d85a284252b4b0e98b04f0bff4"]}},"07746d573ef74d378bedc425a9828053":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e249eaf7a1d42a895520240b21f1fa1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6f2cc7f2328a4962a32368954cbfb921","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":570,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":570,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c308255f6df9488c8a0e8338301fd289"}},"5cd094d85a284252b4b0e98b04f0bff4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d0df7969b0194aeca5ec3fcf5c0fe4be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 570/570 [00:00&lt;00:00, 7.74kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_30d70a77465a40969e7ef99d9e0f84e3"}},"6f2cc7f2328a4962a32368954cbfb921":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c308255f6df9488c8a0e8338301fd289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0df7969b0194aeca5ec3fcf5c0fe4be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"30d70a77465a40969e7ef99d9e0f84e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"znmQhHRL3Xck","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627883547733,"user_tz":-480,"elapsed":23787,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"ad7f42e0-a003-4b66-d106-51de906037ce"},"source":["# Mount Google Drive to Colab\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"--rwD7la3Yjj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627883548813,"user_tz":-480,"elapsed":1089,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"023bf8f1-7d62-4b9e-c0c6-5d3d7a8e0f32"},"source":["!pwd\n","#!ls -al\n","%cd '/content/gdrive/My Drive/NLP/Part2/Day30_Day31/'\n","#!ls -al"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/gdrive/My Drive/NLP/Part2/Day30_Day31\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bWmYuIqwXky9"},"source":["# 作業 : 自行調整完整版 Bert 預訓練模型"]},{"cell_type":"markdown","metadata":{"id":"pjR0X3RKXkzH"},"source":["# [作業目標]\n","- 觀察並了解調整 Step4.3 類神經網路結構對結果帶來的影響\n","- 觀察並了解調整 Step4.2 Batch Size 以及 Step4.4 的Optimizer & Learning Rate 對結果帶來的影響"]},{"cell_type":"markdown","metadata":{"id":"G9OcW6i0XkzI"},"source":["# [作業重點]\n","- 程式最後會輸出 Kaggle 練習題的提交檔, 同學可以藉由提交分數驗證結果\n","- 請同學在修改時, 記得以檔名或其他形式保留調整的紀錄, 以免忘記最佳輸出的調整方式"]},{"cell_type":"markdown","metadata":{"id":"5HiLyC9ZXkzJ"},"source":["# 載入資料與套件, 進行切割與預處理"]},{"cell_type":"code","metadata":{"id":"eVDiQwbCXkzJ","executionInfo":{"status":"ok","timestamp":1627883548814,"user_tz":-480,"elapsed":12,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["# 載入相關套件\n","import os\n","import re, warnings\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings(\"ignore\")\n","%matplotlib inline"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"UngfxH5AXkzK","executionInfo":{"status":"ok","timestamp":1627883550418,"user_tz":-480,"elapsed":1614,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["# 將訓練資料切割成 訓練集 / 驗證集\n","from sklearn.model_selection import train_test_split\n","\n","df =  pd.read_csv('data/train.csv')\n","X = df.text.values\n","y = df.target.values\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=2020)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"v6PqS3WeXkzK","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1627883551014,"user_tz":-480,"elapsed":610,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"d2283ef1-19c8-4536-e7fc-7059e2460147"},"source":["# 載入測試資料\n","test_df = pd.read_csv('data/test.csv')\n","test_df = test_df[['id', 'text']]\n","test_df.sample(5)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1103</th>\n","      <td>3630</td>\n","      <td>'I See Fire' Ed Sheeran The Hobbit: The Desola...</td>\n","    </tr>\n","    <tr>\n","      <th>1648</th>\n","      <td>5550</td>\n","      <td>I see a flattened Cyberman. Do I watch way too...</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>3204</td>\n","      <td>Why are you deluged with low self-image? Take ...</td>\n","    </tr>\n","    <tr>\n","      <th>2788</th>\n","      <td>9279</td>\n","      <td>Sweet jeezus. How is this an election issue?\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>1879</th>\n","      <td>6321</td>\n","      <td>@theCHIVE For the record I held this shirt hos...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                               text\n","1103  3630  'I See Fire' Ed Sheeran The Hobbit: The Desola...\n","1648  5550  I see a flattened Cyberman. Do I watch way too...\n","962   3204  Why are you deluged with low self-image? Take ...\n","2788  9279  Sweet jeezus. How is this an election issue?\\n...\n","1879  6321  @theCHIVE For the record I held this shirt hos..."]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"e_wESyxZXkzM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627883554953,"user_tz":-480,"elapsed":3942,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"3e201ab6-f6c5-463d-f578-833a2fb1a60b"},"source":["# 載入 pytorch 套件, 依照現有環境判定是否使用 GPU 計算\n","import torch\n","\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","Device name: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4P4Azey2XkzN","executionInfo":{"status":"ok","timestamp":1627883557569,"user_tz":-480,"elapsed":3,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["# 簡化版前處理\n","def text_preprocessing(text):\n","    # 移除推特的姓名標籤 ('@name')\n","    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n","    # 將 '&amp;' 替換成 '&'\n","    text = re.sub(r'&amp;', '&', text)\n","    # 移除文末的空白字元\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdhdTZhXXkzN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627883558986,"user_tz":-480,"elapsed":9,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"7fbfed20-fdaa-4b49-ef4b-86ddff60444c"},"source":["# 印出第一組推文在前處理之前與之後的改變\n","print('Original: ', X[0])\n","print('Processed: ', text_preprocessing(X[0]))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n","Processed:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FZYjqFAZXkzN"},"source":["# Step 4.1 : 載入 Bert 套件與 tokenizer, 將本文編碼"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Og2IGnoFMjQa","executionInfo":{"status":"ok","timestamp":1627883566115,"user_tz":-480,"elapsed":6704,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"94fe4be3-7356-4634-b30b-ccc65e3d276f"},"source":["!pip install transformers"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 66.7 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 55.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dnA2rPKYXkzO","colab":{"base_uri":"https://localhost:8080/","height":213,"referenced_widgets":["2338bdd74de9408b8d4fcff802c59846","727dfee5bf384639990b339d903a3492","bd3bea70950c4797b7bcaafe302bb82a","1ae090c199a246548f42b057fd82f049","7e2366b026104e09b31ec0b83db7b32e","b337b16fb42947eea0740bd8180fbd71","de977816d5a74fd2bb02592d1ae9362f","e719d3282f474fc5bb71d35e6b859d4a","17bed22e44304a75b52b4d220d10bc25","338e1f7900b4423ba4ef7189796f7978","58cfc3f4d8cc4371ac645511d59ba80b","b2d181c022ec41cfb7efbe80b4a8c116","680c75b3fd114c1fb028ed40a99bed2d","1dbe43db01314559a86ab6b941f6fd07","2a61ce1b8a814f7ca868f5e0d8ac38ab","e7d8fdada0934c5eb1ba0e0e80a40f45","c0e1245567804a599c8153556c0a04d0","426688c62817440dabcfa1088b7ac138","4894272bbbd74848ad359ffb41b73fa2","782792d7553b4a2ea99b937db1802835","e635c4cb99724085885dbe8f5142dfc7","a09a5595ceec4fb3bbe8bc88d110f91d","8244c443e0734f2f9491d284620544a1","9d032c13b21e4d0dba8bd631804ee941","a27a328d2c4243a5a6e4612528f4bf89","07746d573ef74d378bedc425a9828053","6e249eaf7a1d42a895520240b21f1fa1","5cd094d85a284252b4b0e98b04f0bff4","6f2cc7f2328a4962a32368954cbfb921","c308255f6df9488c8a0e8338301fd289","d0df7969b0194aeca5ec3fcf5c0fe4be","30d70a77465a40969e7ef99d9e0f84e3"]},"executionInfo":{"status":"ok","timestamp":1627883571961,"user_tz":-480,"elapsed":5860,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"2b2bfe7a-4550-42a1-cca9-d0696c8abf41"},"source":["# 載入 Bert 套件與 tokenizer\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","# 設定 Bert 的前處理函數\n","def preprocessing_for_bert(data):\n","    # 初始化要傳回的資料\n","    input_ids = []\n","    attention_masks = []\n","    # 把所有文句用 tokenizer 編碼\n","    for sent in data:\n","        encoded_sent = tokenizer.encode_plus(\n","            text=text_preprocessing(sent),  # 套用簡化版前處理函數\n","            add_special_tokens=True,        # 加上 `[CLS]` 與 `[SEP]`\n","            max_length=MAX_LEN,             # 需要填充的最大長度\n","            pad_to_max_length=True,         # 是否要填充到最大長度\n","            return_attention_mask=True      # 是否傳回 attention mask\n","            )        \n","        # 更新要傳回的資料\n","        input_ids.append(encoded_sent.get('input_ids'))\n","        attention_masks.append(encoded_sent.get('attention_mask'))\n","    # 將傳回資料轉為 tensor\n","    input_ids = torch.tensor(input_ids)\n","    attention_masks = torch.tensor(attention_masks)\n","\n","    return input_ids, attention_masks"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2338bdd74de9408b8d4fcff802c59846","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17bed22e44304a75b52b4d220d10bc25","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c0e1245567804a599c8153556c0a04d0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a27a328d2c4243a5a6e4612528f4bf89","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D9ezEZMyXkzO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627883578040,"user_tz":-480,"elapsed":6092,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"300f2aa7-3f0f-4808-9505-d9e3c543f1d5"},"source":["# 將訓練資料與測試資料的\"推文\"合併\n","all_tweets = np.concatenate([df.text.values, test_df.text.values])\n","\n","# 將推文使用 tokenizer 加以編碼\n","encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n","\n","# 找出最大的推文長度 (訓練資料 + 預測目標資料)\n","max_len = max([len(sent) for sent in encoded_tweets])\n","print('Max length: ', max_len)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Max length:  84\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ov-IWDOKXkzP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627883582534,"user_tz":-480,"elapsed":4510,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"00395411-0af9-49b4-efc0-980005962c65"},"source":["# 將上一格的 Max length 數值填入\n","MAX_LEN = 84\n","\n","# 顯示第一筆資料的推文與期經過 Bert 的前處理函數 (preprocessing_for_bert) 的編碼結果 (確認函數正確)\n","token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n","print('Original: ', X[0])\n","print('Token IDs: ', token_ids)\n","\n","# 使用 preprocessing_for_bert 將訓練 / 驗證集的推文進行編碼\n","print('Tokenizing data...')\n","train_inputs, train_masks = preprocessing_for_bert(X_train)\n","val_inputs, val_masks = preprocessing_for_bert(X_val)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["Original:  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n","Token IDs:  [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Tokenizing data...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zY6IgL0KXkzP"},"source":["# Step 4.2 : Fine Tune 前的準備 - 設定 batch size"]},{"cell_type":"code","metadata":{"id":"2iDpz5UUXkzQ","executionInfo":{"status":"ok","timestamp":1627884637522,"user_tz":-480,"elapsed":246,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# 將訓練與驗證目標值轉為 torch.Tensor\n","train_labels = torch.tensor(y_train)\n","val_labels = torch.tensor(y_val)\n","\n","# 要微調 (fine-tuning) BERT 時, 原作者建議的 batch size 為 16 或 32\n","batch_size = 32\n","\n","# 設定訓練與驗證集的 DataLoader\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","val_data = TensorDataset(val_inputs, val_masks, val_labels)\n","val_sampler = SequentialSampler(val_data)\n","val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xFNtfKhaXkzQ"},"source":["# Step 4.3 : 設定 Bert 連接目標值的 Layer 結構"]},{"cell_type":"code","metadata":{"id":"gyE5aOSjXkzR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627884640202,"user_tz":-480,"elapsed":4,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"70d0be27-1dc4-40f6-9483-9a35c551c80f"},"source":["%%time\n","# 載入 pytorch 與 Bert 相關套件\n","import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","# 自定義 Bert 分類器函數\n","class BertClassifier(nn.Module):\n","    def __init__(self, freeze_bert=False):\n","        super(BertClassifier, self).__init__()\n","        # 指定 BERT 輸入長度大小(D_in), 分類器的隱藏層大小(H), 以及分類目標值的種類數量(D_out)\n","        D_in, H, D_out = 768, 50, 2\n","        # 載入 Bert 預訓練權重作為初始值\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","\n","        # 初始化自定義分類器的類神經網路\n","        self.classifier = nn.Sequential(\n","            nn.Linear(D_in, H),\n","            nn.ReLU(),\n","            #nn.Dropout(0.5),\n","            nn.Linear(H, D_out)\n","        )\n","        # 凍結 Bert 部分的權重\n","        if freeze_bert:\n","            for param in self.bert.parameters():\n","                param.requires_grad = False\n","        \n","    def forward(self, input_ids, attention_mask):\n","        # 將資料輸入 BERT\n","        outputs = self.bert(input_ids=input_ids,\n","                            attention_mask=attention_mask)        \n","        # 將輸出結果存在 last_hidden_state_cls 中\n","        last_hidden_state_cls = outputs[0][:, 0, :]\n","        # 將輸出結果輸入自定義分類器\n","        logits = self.classifier(last_hidden_state_cls)\n","\n","        return logits"],"execution_count":22,"outputs":[{"output_type":"stream","text":["CPU times: user 42 µs, sys: 2 µs, total: 44 µs\n","Wall time: 48.4 µs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VOxS-dcOXkzS"},"source":["# Step 4.4 : Optimizer & Learning Rate"]},{"cell_type":"code","metadata":{"id":"g6ihaa8zXkzS","executionInfo":{"status":"ok","timestamp":1627884923557,"user_tz":-480,"elapsed":449,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","def initialize_model(epochs=4):\n","    # 初始化 Bert 分類器\n","    bert_classifier = BertClassifier(freeze_bert=False)\n","    # 告訴 PyTorch 模型需要在 GPU 上執行\n","    bert_classifier.to(device)\n","    # 設定 optimizer\n","    optimizer = AdamW(bert_classifier.parameters(),\n","                      lr=1e-5,    # 預設的學習速率 5e-5,\n","                      eps=1e-8    # 預設的 epsilon 值 1e-8\n","                      )\n","    # 計算總共的訓練步數\n","    total_steps = len(train_dataloader) * epochs\n","    # 設定學習率排程\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0, # 預設值\n","                                                num_training_steps=total_steps)\n","    return bert_classifier, optimizer, scheduler"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YvwYTdLXkzT","executionInfo":{"status":"ok","timestamp":1627884924309,"user_tz":-480,"elapsed":306,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["import random\n","import time\n","\n","# 設定損失函數\n","loss_fn = nn.CrossEntropyLoss()\n","def set_seed(seed_value=42):\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n","    # 開始訓練迴圈\n","    print(\"Start training...\\n\")\n","    for epoch_i in range(epochs):\n","        # 印出變數表格標題\n","        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n","        print(\"-\"*70)\n","        # 測量每個 epoch 的執行時間\n","        t0_epoch, t0_batch = time.time(), time.time()\n","        # 每個 epoch 開始時重置追蹤的變數\n","        total_loss, batch_loss, batch_counts = 0, 0, 0\n","        # 將模型切換到訓練模式\n","        model.train()\n","        # 訓練資料的每個 batch \n","        for step, batch in enumerate(train_dataloader):\n","            batch_counts +=1\n","            # 將所有 batch 資料載入 GPU\n","            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","            # 將模型中之前計算的梯度歸零\n","            model.zero_grad()\n","            # 執行一個向前傳遞. 這會傳回一個 logit 值\n","            logits = model(b_input_ids, b_attn_mask)\n","            # 計算並累加損失值\n","            loss = loss_fn(logits, b_labels)\n","            batch_loss += loss.item()\n","            total_loss += loss.item()\n","            # 執行一個向後傳遞以計算梯度\n","            loss.backward()\n","            # 將梯度侷限在正負 1 範圍內, 防止梯度爆炸\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            # 更新參數與學習率\n","            optimizer.step()\n","            scheduler.step()\n","            # 每 20 個 batches 印出損失值與執行時間一次\n","            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n","                # 計算 20 batches 的執行時間\n","                time_elapsed = time.time() - t0_batch\n","                # 印出訓練結果\n","                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n","                # 重置 batch 追蹤變數\n","                batch_loss, batch_counts = 0, 0\n","                t0_batch = time.time()\n","        # 計算全部訓練資料的平均損失值\n","        avg_train_loss = total_loss / len(train_dataloader)\n","\n","        print(\"-\"*70)\n","        if evaluation == True:\n","            # 每個 epoch 訓練完畢後, 在驗證集上檢驗模型的表現\n","            val_loss, val_accuracy = evaluate(model, val_dataloader)\n","            time_elapsed = time.time() - t0_epoch            \n","            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n","            print(\"-\"*70)\n","        print(\"\\n\")    \n","    print(\"Training complete!\")\n","\n","def evaluate(model, val_dataloader):\n","    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n","    model.eval()\n","    # 紀錄評量函數\n","    val_accuracy = []\n","    val_loss = []\n","    # 驗證資料的每個 batch \n","    for batch in val_dataloader:\n","        # 將所有 batch 資料載入 GPU\n","        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n","        # 計算 logit 值\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        # 計算損失值\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","        # 取得預測值\n","        preds = torch.argmax(logits, dim=1).flatten()\n","        # 計算 accuracy 數值\n","        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n","        val_accuracy.append(accuracy)\n","    # 計算全部驗證資料的平均損失值與平均 accuracy\n","    val_loss = np.mean(val_loss)\n","    val_accuracy = np.mean(val_accuracy)\n","    return val_loss, val_accuracy"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mkh_UvM2XkzU"},"source":["# 執行跑參 : 依機器的計算能力調整 epoch 大小"]},{"cell_type":"code","metadata":{"id":"F2pkguY7XkzU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627885801092,"user_tz":-480,"elapsed":876324,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"0d712a4f-e7e8-4d5c-9243-e0bb8b4883bb"},"source":["set_seed(42) # 設定隨機種子\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=8)\n","train(bert_classifier, train_dataloader, val_dataloader, epochs=8, evaluation=True)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   1    |   20    |   0.536391   |     -      |     -     |   10.22  \n","   1    |   40    |   0.478991   |     -      |     -     |   10.17  \n","   1    |   60    |   0.417504   |     -      |     -     |   10.48  \n","   1    |   80    |   0.459344   |     -      |     -     |   10.21  \n","   1    |   100   |   0.393025   |     -      |     -     |   9.94   \n","   1    |   120   |   0.400106   |     -      |     -     |   9.75   \n","   1    |   140   |   0.438050   |     -      |     -     |   9.65   \n","   1    |   160   |   0.431070   |     -      |     -     |   9.66   \n","   1    |   180   |   0.402223   |     -      |     -     |   9.73   \n","   1    |   200   |   0.444094   |     -      |     -     |   9.79   \n","   1    |   214   |   0.409324   |     -      |     -     |   6.51   \n","----------------------------------------------------------------------\n","   1    |    -    |   0.438525   |  0.414060  |   82.59   |  110.27  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   2    |   20    |   0.314777   |     -      |     -     |   10.41  \n","   2    |   40    |   0.278313   |     -      |     -     |   9.90   \n","   2    |   60    |   0.280994   |     -      |     -     |   9.88   \n","   2    |   80    |   0.284255   |     -      |     -     |   9.84   \n","   2    |   100   |   0.329499   |     -      |     -     |   9.78   \n","   2    |   120   |   0.291888   |     -      |     -     |   9.78   \n","   2    |   140   |   0.321863   |     -      |     -     |   9.78   \n","   2    |   160   |   0.354368   |     -      |     -     |   9.80   \n","   2    |   180   |   0.337481   |     -      |     -     |   9.81   \n","   2    |   200   |   0.304392   |     -      |     -     |   9.80   \n","   2    |   214   |   0.348984   |     -      |     -     |   6.47   \n","----------------------------------------------------------------------\n","   2    |    -    |   0.312359   |  0.474652  |   81.10   |  109.38  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   3    |   20    |   0.189750   |     -      |     -     |   10.27  \n","   3    |   40    |   0.248649   |     -      |     -     |   9.82   \n","   3    |   60    |   0.227784   |     -      |     -     |   9.83   \n","   3    |   80    |   0.249280   |     -      |     -     |   9.83   \n","   3    |   100   |   0.206693   |     -      |     -     |   9.84   \n","   3    |   120   |   0.224120   |     -      |     -     |   9.85   \n","   3    |   140   |   0.216075   |     -      |     -     |   9.85   \n","   3    |   160   |   0.210418   |     -      |     -     |   9.86   \n","   3    |   180   |   0.211951   |     -      |     -     |   9.84   \n","   3    |   200   |   0.220827   |     -      |     -     |   9.85   \n","   3    |   214   |   0.198155   |     -      |     -     |   6.50   \n","----------------------------------------------------------------------\n","   3    |    -    |   0.218953   |  0.592000  |   81.52   |  109.49  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   4    |   20    |   0.159326   |     -      |     -     |   10.33  \n","   4    |   40    |   0.123416   |     -      |     -     |   9.85   \n","   4    |   60    |   0.176543   |     -      |     -     |   9.83   \n","   4    |   80    |   0.152711   |     -      |     -     |   9.82   \n","   4    |   100   |   0.150983   |     -      |     -     |   9.82   \n","   4    |   120   |   0.143426   |     -      |     -     |   9.82   \n","   4    |   140   |   0.127941   |     -      |     -     |   9.81   \n","   4    |   160   |   0.174328   |     -      |     -     |   9.83   \n","   4    |   180   |   0.180397   |     -      |     -     |   9.81   \n","   4    |   200   |   0.158332   |     -      |     -     |   9.81   \n","   4    |   214   |   0.228109   |     -      |     -     |   6.48   \n","----------------------------------------------------------------------\n","   4    |    -    |   0.159539   |  0.565479  |   80.87   |  109.34  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   5    |   20    |   0.120392   |     -      |     -     |   10.28  \n","   5    |   40    |   0.121763   |     -      |     -     |   9.79   \n","   5    |   60    |   0.117686   |     -      |     -     |   9.83   \n","   5    |   80    |   0.109425   |     -      |     -     |   9.81   \n","   5    |   100   |   0.063804   |     -      |     -     |   9.80   \n","   5    |   120   |   0.097172   |     -      |     -     |   9.81   \n","   5    |   140   |   0.104342   |     -      |     -     |   9.80   \n","   5    |   160   |   0.127420   |     -      |     -     |   9.85   \n","   5    |   180   |   0.121327   |     -      |     -     |   9.83   \n","   5    |   200   |   0.093077   |     -      |     -     |   9.81   \n","   5    |   214   |   0.100153   |     -      |     -     |   6.45   \n","----------------------------------------------------------------------\n","   5    |    -    |   0.107213   |  0.701682  |   80.15   |  109.18  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   6    |   20    |   0.045979   |     -      |     -     |   10.21  \n","   6    |   40    |   0.102827   |     -      |     -     |   9.75   \n","   6    |   60    |   0.099650   |     -      |     -     |   9.77   \n","   6    |   80    |   0.096844   |     -      |     -     |   9.80   \n","   6    |   100   |   0.075645   |     -      |     -     |   9.80   \n","   6    |   120   |   0.063491   |     -      |     -     |   9.83   \n","   6    |   140   |   0.055560   |     -      |     -     |   9.80   \n","   6    |   160   |   0.077172   |     -      |     -     |   9.81   \n","   6    |   180   |   0.080443   |     -      |     -     |   9.81   \n","   6    |   200   |   0.068402   |     -      |     -     |   9.77   \n","   6    |   214   |   0.144193   |     -      |     -     |   6.47   \n","----------------------------------------------------------------------\n","   6    |    -    |   0.080860   |  0.841185  |   82.30   |  108.95  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   7    |   20    |   0.054687   |     -      |     -     |   10.24  \n","   7    |   40    |   0.082142   |     -      |     -     |   9.76   \n","   7    |   60    |   0.048830   |     -      |     -     |   9.74   \n","   7    |   80    |   0.063682   |     -      |     -     |   9.75   \n","   7    |   100   |   0.083667   |     -      |     -     |   9.77   \n","   7    |   120   |   0.043586   |     -      |     -     |   9.78   \n","   7    |   140   |   0.056466   |     -      |     -     |   9.77   \n","   7    |   160   |   0.055400   |     -      |     -     |   9.76   \n","   7    |   180   |   0.043876   |     -      |     -     |   9.77   \n","   7    |   200   |   0.043681   |     -      |     -     |   9.76   \n","   7    |   214   |   0.074962   |     -      |     -     |   6.44   \n","----------------------------------------------------------------------\n","   7    |    -    |   0.058719   |  0.967636  |   81.39   |  108.65  \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   8    |   20    |   0.035269   |     -      |     -     |   10.24  \n","   8    |   40    |   0.042644   |     -      |     -     |   9.74   \n","   8    |   60    |   0.036007   |     -      |     -     |   9.76   \n","   8    |   80    |   0.037759   |     -      |     -     |   9.76   \n","   8    |   100   |   0.052145   |     -      |     -     |   9.77   \n","   8    |   120   |   0.042963   |     -      |     -     |   9.78   \n","   8    |   140   |   0.033929   |     -      |     -     |   9.77   \n","   8    |   160   |   0.033913   |     -      |     -     |   9.77   \n","   8    |   180   |   0.026265   |     -      |     -     |   9.77   \n","   8    |   200   |   0.048952   |     -      |     -     |   9.78   \n","   8    |   214   |   0.043055   |     -      |     -     |   6.45   \n","----------------------------------------------------------------------\n","   8    |    -    |   0.039232   |  0.993908  |   81.68   |  108.72  \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EaxNnaM4XkzU"},"source":["# 繪製 ROC_AUC 圖形 : 藉此觀察預測效果"]},{"cell_type":"code","metadata":{"id":"phdGa5X5XkzU","executionInfo":{"status":"ok","timestamp":1627885801093,"user_tz":-480,"elapsed":18,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["import torch.nn.functional as F\n","\n","def bert_predict(model, test_dataloader):\n","    # 將模型切換到評量模式 : 此模式下暫停使用 dropout 層\n","    model.eval()\n","    all_logits = []\n","\n","    # 測試資料的每個 batch \n","    for batch in test_dataloader:\n","        # 將所有 batch 資料載入 GPU\n","        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n","        # 計算機率\n","        with torch.no_grad():\n","            logits = model(b_input_ids, b_attn_mask)\n","        all_logits.append(logits)    \n","    # 將每個 batch 的 logit 值連結起來\n","    all_logits = torch.cat(all_logits, dim=0)\n","    # 使用 softmax 計算機率\n","    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n","    return probs"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nK6w-NyXkzV","executionInfo":{"status":"ok","timestamp":1627885801094,"user_tz":-480,"elapsed":6,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["from sklearn.metrics import accuracy_score, roc_curve, auc\n","\n","def evaluate_roc(probs, y_true):\n","    preds = probs[:, 1]\n","    fpr, tpr, threshold = roc_curve(y_true, preds)\n","    roc_auc = auc(fpr, tpr)\n","    print(f'AUC: {roc_auc:.4f}')       \n","    # 取得測試集的 accuracy 值\n","    y_pred = np.where(preds >= 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy*100:.2f}%')    \n","    # 繪製 ROC AUC\n","    plt.title('Receiver Operating Characteristic')\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5Rx4KwpXkzV","colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"status":"ok","timestamp":1627885805587,"user_tz":-480,"elapsed":4499,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"9d53fc93-22fd-4e2d-cc67-ec92801690dc"},"source":["# 在測試集上計算預測機率\n","probs = bert_predict(bert_classifier, val_dataloader)\n","# 評價 Bert 分類器\n","evaluate_roc(probs, y_val)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["AUC: 0.8550\n","Accuracy: 81.63%\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"o3FtqgxMXkzW"},"source":["# 重新以完整資料訓練模型, 並對要預測的資料進行輸出"]},{"cell_type":"code","metadata":{"id":"B0KT0n72XkzW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627886661928,"user_tz":-480,"elapsed":226806,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"4bde271c-b0be-4042-a08c-d99b4baa6fe3"},"source":["# 連結訓練集與驗證集\n","full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n","full_train_sampler = RandomSampler(full_train_data)\n","full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n","\n","# 在完整的訓練資料上重新訓練 Bert 分類器\n","set_seed(42)\n","bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n","train(bert_classifier, full_train_dataloader, epochs=2)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["Start training...\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   1    |   20    |   0.601928   |     -      |     -     |   9.28   \n","   1    |   40    |   0.487405   |     -      |     -     |   8.92   \n","   1    |   60    |   0.438320   |     -      |     -     |   8.95   \n","   1    |   80    |   0.444691   |     -      |     -     |   9.03   \n","   1    |   100   |   0.441509   |     -      |     -     |   9.13   \n","   1    |   120   |   0.414502   |     -      |     -     |   9.23   \n","   1    |   140   |   0.417610   |     -      |     -     |   9.33   \n","   1    |   160   |   0.405342   |     -      |     -     |   9.33   \n","   1    |   180   |   0.418427   |     -      |     -     |   9.33   \n","   1    |   200   |   0.433513   |     -      |     -     |   9.34   \n","   1    |   220   |   0.365013   |     -      |     -     |   9.38   \n","   1    |   237   |   0.380409   |     -      |     -     |   8.01   \n","----------------------------------------------------------------------\n","\n","\n"," Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n","----------------------------------------------------------------------\n","   2    |   20    |   0.266579   |     -      |     -     |   9.98   \n","   2    |   40    |   0.258938   |     -      |     -     |   9.55   \n","   2    |   60    |   0.258300   |     -      |     -     |   9.61   \n","   2    |   80    |   0.288447   |     -      |     -     |   9.64   \n","   2    |   100   |   0.270524   |     -      |     -     |   9.69   \n","   2    |   120   |   0.270223   |     -      |     -     |   9.69   \n","   2    |   140   |   0.243730   |     -      |     -     |   9.72   \n","   2    |   160   |   0.259149   |     -      |     -     |   9.75   \n","   2    |   180   |   0.238117   |     -      |     -     |   9.76   \n","   2    |   200   |   0.281829   |     -      |     -     |   9.77   \n","   2    |   220   |   0.284671   |     -      |     -     |   9.82   \n","   2    |   237   |   0.327358   |     -      |     -     |   8.32   \n","----------------------------------------------------------------------\n","\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"42F9JoIzXkzX","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1627886661930,"user_tz":-480,"elapsed":16,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"5ef0cf6e-bc48-4d7d-801a-a607a28f0724"},"source":["test_df.sample(5)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2406</th>\n","      <td>8051</td>\n","      <td>Refugees as citizens - The Hindu http://t.co/G...</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>425</td>\n","      <td>@5SOStag honestly he could say an apocalypse i...</td>\n","    </tr>\n","    <tr>\n","      <th>411</th>\n","      <td>1330</td>\n","      <td>If you bored as shit don't nobody fuck wit you...</td>\n","    </tr>\n","    <tr>\n","      <th>203</th>\n","      <td>663</td>\n","      <td>@RealTwanBrown Yesterday I Had A Heat Attack ?...</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>2930</td>\n","      <td>The Devil Wears Prada is still one of my favou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                               text\n","2406  8051  Refugees as citizens - The Hindu http://t.co/G...\n","134    425  @5SOStag honestly he could say an apocalypse i...\n","411   1330  If you bored as shit don't nobody fuck wit you...\n","203    663  @RealTwanBrown Yesterday I Had A Heat Attack ?...\n","889   2930  The Devil Wears Prada is still one of my favou..."]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"8imzaomzXkzY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627886663769,"user_tz":-480,"elapsed":1850,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"6339a948-7ec2-4fbd-c205-0f6d095c5205"},"source":["# 在測試集推文上執行 `preprocessing_for_bert` 函數\n","print('Tokenizing data...')\n","test_inputs, test_masks = preprocessing_for_bert(test_df['text'])\n","# 宣告測試集的 DataLoader\n","test_dataset = TensorDataset(test_inputs, test_masks)\n","test_sampler = SequentialSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Tokenizing data...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AM4o-sxDXkzZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627886681419,"user_tz":-480,"elapsed":17654,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}},"outputId":"269faa0d-f26c-4f80-93fb-646891170655"},"source":["# 在測試資料上計算最終預測機率\n","probs = bert_predict(bert_classifier, test_dataloader)\n","# 將機率值轉為預測(超過門檻的預測為 1, 否則為 0)\n","threshold = 0.9\n","preds = np.where(probs[:, 1] > threshold, 1, 0)\n","# 顯示被判定為\n","print(\"Number of tweets predicted non-negative: \", preds.sum())"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Number of tweets predicted non-negative:  916\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mtjcf_WwXkza","executionInfo":{"status":"ok","timestamp":1627886681832,"user_tz":-480,"elapsed":433,"user":{"displayName":"Tu Belle 芮妍_Rebecca 芮瑩","photoUrl":"","userId":"13639675632472162428"}}},"source":["# 生成提交擋\n","submission = pd.DataFrame()\n","submission['id'] = test_df['id']\n","submission['target'] = preds\n","submission.to_csv('submission_FineTuneBert.csv', index=False)"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_a_1BDeXkza"},"source":[""],"execution_count":null,"outputs":[]}]}